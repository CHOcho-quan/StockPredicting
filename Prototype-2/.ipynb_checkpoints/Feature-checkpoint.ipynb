{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation\n",
    "We use linear combination, wavelet transformation, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from data_reader import DataLoader\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "N = 10\n",
    "seq_len = 30\n",
    "sample_gap = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we try to use data generated by linear combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15091, 30, 21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, return_sequences=True, input_shape=(30, 21))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 30, 128)           76800     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 113,121\n",
      "Trainable params: 113,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 38s 3ms/step - loss: 2.2239 - val_loss: 2.1747\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 33s 2ms/step - loss: 2.2125 - val_loss: 2.1430\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 33s 2ms/step - loss: 2.2111 - val_loss: 2.1481\n",
      "LSTM:  1.6081407225734152\n"
     ]
    }
   ],
   "source": [
    "def LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_length=train_input.shape[1], input_dim=train_input.shape[2], return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    LSTMIndicatorPred = model.predict(test_input)\n",
    "    LSTMacc = np.std(LSTMIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return LSTMacc\n",
    "\n",
    "if os.path.exists(path=\"./raw_data/featuredata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./raw_data/featuredata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    dataset = get_fromcsv(root)\n",
    "    dataset = clean_data(dataset)\n",
    "    dataset, labels = get_feature_label(dataset, N, seq_len, sample_gap)\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = divid_dataset(dataset, labels)\n",
    "    with open(\"./raw_data/featuredata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "\n",
    "train_input = np.array(train_input).reshape(train_input.shape[0], seq_len, -1)\n",
    "train_label = np.array(train_label)\n",
    "dev_input = np.array(dev_input).reshape(dev_input.shape[0], seq_len, -1)\n",
    "dev_label = np.array(dev_label)\n",
    "test_input = np.array(test_input).reshape(test_input.shape[0], seq_len, -1)\n",
    "test_label = np.array(test_label)\n",
    "print(train_input.shape)\n",
    "accs = []\n",
    "\n",
    "LSTMacc1 = LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(\"LSTM: \", LSTMacc1)\n",
    "accs.append(LSTMacc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 5, 32)         896       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 3, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                4170      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 14,325\n",
      "Trainable params: 14,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 7s 462us/step - loss: 2.2600 - val_loss: 2.1544\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 6s 383us/step - loss: 2.2152 - val_loss: 2.1556\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 6s 391us/step - loss: 2.2078 - val_loss: 2.1402\n",
      "1.6086419436201185\n"
     ]
    }
   ],
   "source": [
    "def CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    train_input = train_input.reshape(train_input.shape[0], train_input.shape[1], int(train_input.shape[2] / 3), 3)\n",
    "    test_input = test_input.reshape(test_input.shape[0], test_input.shape[1], int(test_input.shape[2] / 3), 3)\n",
    "    dev_input = dev_input.reshape(dev_input.shape[0], dev_input.shape[1], int(dev_input.shape[2] / 3), 3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid', input_shape=(train_input.shape[1], train_input.shape[2], train_input.shape[3])))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "#     model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    CNNIndicatorPred = model.predict(test_input)\n",
    "    CNNacc = np.std(CNNIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return CNNacc\n",
    "\n",
    "CNNacc1 = CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(CNNacc1)\n",
    "accs.append(CNNacc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT:  1.6094588567358585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def GBDTRegress(X, y, depth, random_st):\n",
    "    regr = GradientBoostingRegressor(max_depth=depth, random_state=random_st)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "train_input = train_input.reshape(train_input.shape[0], -1)\n",
    "dev_input = dev_input.reshape(dev_input.shape[0], -1)\n",
    "test_input = test_input.reshape(test_input.shape[0], -1)\n",
    "\n",
    "regressor = GBDTRegress(train_input, np.array(train_label), 2, 0)\n",
    "\n",
    "GBDTRawPred = regressor.predict(test_input)\n",
    "GBDTacc1 = np.std(GBDTRawPred - np.array(test_label))\n",
    "print(\"GBDT: \", GBDTacc1)\n",
    "accs.append(GBDTacc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  1.6068420474914324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def RandomForestRegress(X, y, depth, random_st, n_estimators):\n",
    "    regr = RandomForestRegressor(max_depth=depth, random_state=random_st, n_estimators=n_estimators)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "regressor = RandomForestRegress(train_input, np.array(train_label), 2, 0, 100)\n",
    "\n",
    "RFRawPred = regressor.predict(test_input)\n",
    "RFacc1 = np.std(RFRawPred - np.array(test_label))\n",
    "print(\"Random Forest: \", RFacc1)\n",
    "accs.append(RFacc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:  1.7902172858739314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "def AdaRegress(X, y, n_estimators, random_st):\n",
    "    regr = AdaBoostRegressor(n_estimators=n_estimators, random_state=random_st)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "regressor = AdaRegress(train_input, np.array(train_label), 100, 0)\n",
    "\n",
    "AdaRawPred = regressor.predict(test_input)\n",
    "AdaBoostacc1 = np.std(AdaRawPred - np.array(test_label))\n",
    "print(\"AdaBoost: \", AdaBoostacc1)\n",
    "accs.append(AdaBoostacc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we try to use data generated by wavelet transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, return_sequences=True, input_shape=(30, 108))`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 30, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 68s 5ms/step - loss: 2.2866 - val_loss: 2.2366\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 65s 4ms/step - loss: 2.2595 - val_loss: 2.2340\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 64s 4ms/step - loss: 2.2542 - val_loss: 2.2471\n",
      "LSTM:  1.452959518939123\n"
     ]
    }
   ],
   "source": [
    "import pywt\n",
    "\n",
    "def wavelet_denoising(data):\n",
    "    \"\"\"\n",
    "    Doing wavelet transformation for single data\n",
    "\n",
    "    \"\"\"\n",
    "    db4 = pywt.Wavelet('db4')\n",
    "    coeffs = pywt.wavedec(data, db4)\n",
    "    coeffs[len(coeffs) - 1] *= 0\n",
    "    coeffs[len(coeffs) - 2] *= 0\n",
    "    meta = pywt.waverec(coeffs, db4)\n",
    "    return meta\n",
    "\n",
    "def generate_by_wavelet(N, seq_len, sample_gap):\n",
    "    \"\"\"\n",
    "    Generating features by wavelet transformation\n",
    "\n",
    "    \"\"\"\n",
    "    if os.path.exists(path=\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "        with open(\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "            (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "    else:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "        with open(\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "            data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "            pickle.dump(data_list, save_data)\n",
    "            \n",
    "    train_input = np.array(train_input).reshape(train_input.shape[0], seq_len, -1)\n",
    "    train_label = np.array(train_label)\n",
    "    dev_input = np.array(dev_input).reshape(dev_input.shape[0], seq_len, -1)\n",
    "    dev_label = np.array(dev_label)\n",
    "    test_input = np.array(test_input).reshape(test_input.shape[0], seq_len, -1)\n",
    "    test_label = np.array(test_label)\n",
    "    \n",
    "    for i in range(train_input.shape[2]):\n",
    "        train_input[:, :, i] = wavelet_denoising(train_input[:, :, i])\n",
    "        dev_input[:, :, i] = wavelet_denoising(dev_input[:, :, i])\n",
    "        test_input[:, :, i] = wavelet_denoising(test_input[:, :, i])\n",
    "\n",
    "    return train_input, train_label, dev_input, dev_label, test_input, test_label\n",
    "\n",
    "train_input, train_label, dev_input, dev_label, test_input, test_label = generate_by_wavelet(N, seq_len, sample_gap)\n",
    "accs2 = []\n",
    "\n",
    "LSTMacc2 = LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(\"LSTM: \", LSTMacc2)\n",
    "accs2.append(LSTMacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 34, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 26, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6656)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                66570     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 76,725\n",
      "Trainable params: 76,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 63s 4ms/step - loss: 2.8204 - val_loss: 2.2511\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 58s 4ms/step - loss: 2.2764 - val_loss: 2.2385\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 55s 4ms/step - loss: 2.2617 - val_loss: 2.2331\n",
      "1.452655450670369\n"
     ]
    }
   ],
   "source": [
    "CNNacc2 = CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(CNNacc2)\n",
    "accs2.append(CNNacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT:  1.4563132787585513\n"
     ]
    }
   ],
   "source": [
    "train_input = train_input.reshape(train_input.shape[0], -1)\n",
    "dev_input = dev_input.reshape(dev_input.shape[0], -1)\n",
    "test_input = test_input.reshape(test_input.shape[0], -1)\n",
    "\n",
    "regressor = GBDTRegress(train_input, np.array(train_label), 2, 0)\n",
    "\n",
    "GBDTRawPred = regressor.predict(test_input)\n",
    "GBDTacc2 = np.std(GBDTRawPred - np.array(test_label))\n",
    "print(\"GBDT: \", GBDTacc2)\n",
    "accs2.append(GBDTacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:  1.448364060692664\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegress(train_input, np.array(train_label), 2, 0, 100)\n",
    "\n",
    "RFRawPred = regressor.predict(test_input)\n",
    "RFacc2 = np.std(RFRawPred - np.array(test_label))\n",
    "print(\"Random Forest: \", RFacc2)\n",
    "accs2.append(RFacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost:  1.5211327854712615\n"
     ]
    }
   ],
   "source": [
    "regressor = AdaRegress(train_input, np.array(train_label), 100, 0)\n",
    "\n",
    "AdaRawPred = regressor.predict(test_input)\n",
    "AdaBoostacc2 = np.std(AdaRawPred - np.array(test_label))\n",
    "print(\"AdaBoost: \", AdaBoostacc2)\n",
    "accs2.append(AdaBoostacc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we try to use package featuretools to generate some more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:71: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:71: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, return_sequences=True, input_shape=(30, 57))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 128)           95232     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 131,553\n",
      "Trainable params: 131,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 31s 2ms/step - loss: 2.2185 - val_loss: 2.3092\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 31s 2ms/step - loss: 2.2109 - val_loss: 2.3150\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 27s 2ms/step - loss: 2.2096 - val_loss: 2.3109\n",
      "LSTM:  1.555273279358649\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 55, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 53, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 26, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 10816)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                108170    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 117,749\n",
      "Trainable params: 117,749\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 53s 3ms/step - loss: 7.5377 - val_loss: 2.5318\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 56s 4ms/step - loss: 2.2594 - val_loss: 2.3279\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 60s 4ms/step - loss: 2.2310 - val_loss: 2.3422\n",
      "1.5543069315652556\n",
      "GBDT:  1.5725499735534914\n",
      "Random Forest:  1.5573987930745823\n",
      "AdaBoost:  1.6437678384033398\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "\n",
    "if os.path.exists(path=\"./raw_data/ftdata.pickle\"):\n",
    "    with open(\"./raw_data/ftdata.pickle\", 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "    with open(\"./raw_data/ftdata.pickle\", 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "\n",
    "train_input = train_input[~np.isnan(train_input)].reshape(int(train_input.shape[0] / 30), -1)     \n",
    "dev_input = dev_input[~np.isnan(dev_input)].reshape(int(dev_input.shape[0] / 30), -1)     \n",
    "test_input = test_input[~np.isnan(test_input)].reshape(int(test_input.shape[0] / 30), -1)     \n",
    "\n",
    "train_input = np.array(train_input).reshape(train_input.shape[0], seq_len, -1)\n",
    "train_label = np.array(train_label)\n",
    "dev_input = np.array(dev_input).reshape(dev_input.shape[0], seq_len, -1)\n",
    "dev_label = np.array(dev_label)\n",
    "test_input = np.array(test_input).reshape(test_input.shape[0], seq_len, -1)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "def CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    train_input = train_input.reshape(train_input.shape[0], train_input.shape[1], int(train_input.shape[2]), 1)\n",
    "    test_input = test_input.reshape(test_input.shape[0], test_input.shape[1], int(test_input.shape[2]), 1)\n",
    "    dev_input = dev_input.reshape(dev_input.shape[0], dev_input.shape[1], int(dev_input.shape[2]), 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid', input_shape=(train_input.shape[1], train_input.shape[2], train_input.shape[3])))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "#     model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    CNNIndicatorPred = model.predict(test_input)\n",
    "    CNNacc = np.std(CNNIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return CNNacc\n",
    "\n",
    "accs3 = []\n",
    "\n",
    "LSTMacc3 = LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "accs3.append(LSTMacc3)\n",
    "print(\"LSTM: \", LSTMacc3)\n",
    "\n",
    "CNNacc3 = CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(CNNacc3)\n",
    "accs3.append(CNNacc3)\n",
    "\n",
    "train_input = train_input.reshape(train_input.shape[0], -1)\n",
    "dev_input = dev_input.reshape(dev_input.shape[0], -1)\n",
    "test_input = test_input.reshape(test_input.shape[0], -1)\n",
    "\n",
    "regressor = GBDTRegress(train_input, np.array(train_label), 2, 0)\n",
    "GBDTRawPred = regressor.predict(test_input)\n",
    "GBDTacc3 = np.std(GBDTRawPred - np.array(test_label))\n",
    "print(\"GBDT: \", GBDTacc3)\n",
    "accs3.append(GBDTacc3)\n",
    "\n",
    "regressor = RandomForestRegress(train_input, np.array(train_label), 2, 0, 100)\n",
    "RFRawPred = regressor.predict(test_input)\n",
    "RFacc3 = np.std(RFRawPred - np.array(test_label))\n",
    "print(\"Random Forest: \", RFacc3)\n",
    "accs3.append(RFacc3)\n",
    "\n",
    "regressor = AdaRegress(train_input, np.array(train_label), 100, 0)\n",
    "AdaRawPred = regressor.predict(test_input)\n",
    "AdaBoostacc3 = np.std(AdaRawPred - np.array(test_label))\n",
    "print(\"AdaBoost: \", AdaBoostacc3)\n",
    "accs3.append(AdaBoostacc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x12b455a20>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "raw_data_accs = [1.6420239050048966, 1.6406177202536136, 1.6412394080028718, 1.6199134532344999, 1.6783490146996896]\n",
    "plt.figure()\n",
    "plt.plot(['LSTM', 'CNN', 'GBDT', 'RandomForest', 'AdaBoost'], accs, color='red', label='Linear Transformation')\n",
    "plt.plot(['LSTM', 'CNN', 'GBDT', 'RandomForest', 'AdaBoost'], accs2, color='blue', label='Wavelet Transformation')\n",
    "plt.plot(['LSTM', 'CNN', 'GBDT', 'RandomForest', 'AdaBoost'], accs3, color='yellow', label='Feature Tools')\n",
    "plt.plot(['LSTM', 'CNN', 'GBDT', 'RandomForest', 'AdaBoost'], raw_data_accs, color='green', label='Original Data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we try to use wt, SAE & LSTM to do stock predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15091, 30, 28)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "First Step : Using Wavelet Transformation to wipe out noise\n",
    "\"\"\"\n",
    "train_input, train_label, dev_input, dev_label, test_input, test_label = generate_by_wavelet(N, seq_len, sample_gap)\n",
    "print(train_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 128)               107648    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 840)               108360    \n",
      "=================================================================\n",
      "Total params: 216,008\n",
      "Trainable params: 216,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/5\n",
      "15091/15091 [==============================] - 3s 184us/step - loss: 0.7711 - val_loss: 0.7309\n",
      "Epoch 2/5\n",
      "15091/15091 [==============================] - 1s 93us/step - loss: 0.7300 - val_loss: 0.7308\n",
      "Epoch 3/5\n",
      "15091/15091 [==============================] - 1s 93us/step - loss: 0.7299 - val_loss: 0.7308\n",
      "Epoch 4/5\n",
      "15091/15091 [==============================] - 2s 102us/step - loss: 0.7299 - val_loss: 0.7308\n",
      "Epoch 5/5\n",
      "15091/15091 [==============================] - 2s 110us/step - loss: 0.7296 - val_loss: 0.7300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12fe42e48>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Second Step : Using SAE to get high level features\n",
    "\"\"\"\n",
    "train_input = train_input.reshape(train_input.shape[0], -1)\n",
    "train_input -= np.mean(train_input)\n",
    "train_input /= np.std(train_input)\n",
    "\n",
    "dev_input = dev_input.reshape(dev_input.shape[0], -1)\n",
    "dev_input -= np.mean(dev_input)\n",
    "dev_input /= np.std(dev_input)\n",
    "\n",
    "test_input = test_input.reshape(test_input.shape[0], -1)\n",
    "test_input -= np.mean(test_input)\n",
    "test_input /= np.std(test_input)\n",
    "\n",
    "SAE = Sequential()\n",
    "\n",
    "SAE.add(Dense(128, input_shape=(840, ), activation='relu'))\n",
    "SAE.add(Dense(840, activation='sigmoid'))\n",
    "\n",
    "SAE.compile(optimizer='adam', loss='mse')\n",
    "SAE.summary()\n",
    "\n",
    "SAE.fit(train_input, train_input, epochs=5, batch_size=128, verbose=1, validation_data=(dev_input, dev_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:6: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:6: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, return_sequences=True, input_shape=(30, 28))`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 128)           80384     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 116,705\n",
      "Trainable params: 116,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 49s 3ms/step - loss: 2.2097 - val_loss: 2.3102\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 45s 3ms/step - loss: 2.2075 - val_loss: 2.3094\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 46s 3ms/step - loss: 2.2072 - val_loss: 2.3093\n",
      "1.5552419554584314\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Third Step : Using LSTM to do regression\n",
    "\"\"\"\n",
    "def LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_length=train_input.shape[1], input_dim=train_input.shape[2], return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    LSTMIndicatorPred = model.predict(test_input)\n",
    "    LSTMacc = np.std(LSTMIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return LSTMacc\n",
    "\n",
    "new_train = SAE.predict(train_input)\n",
    "new_dev = SAE.predict(dev_input)\n",
    "new_test = SAE.predict(test_input)\n",
    "\n",
    "new_train = new_train.reshape(new_train.shape[0], seq_len, 28)\n",
    "new_dev = new_dev.reshape(new_dev.shape[0], seq_len, 28)\n",
    "new_test = new_test.reshape(new_test.shape[0], seq_len, 28)\n",
    "\n",
    "acc = LSTMModel(new_train, train_label, new_dev, dev_label, new_test, test_label)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
