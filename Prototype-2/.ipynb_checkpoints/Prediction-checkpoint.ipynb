{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Predicting\n",
    "We have used several methods to implement the prediction. The data are seperated into 2 parts where the first part is about the indicators and the second part is about the raw data. The raw data will be used by feature tools later to generate some amazing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv, datetime, time, random\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from data_reader import DataLoader\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "import os, pickle\n",
    "from data_reader import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP = ''\n",
    "\n",
    "class Data():\n",
    "    \"\"\"\n",
    "    Loading a single line of the data\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.fv = [float(d) for d in data[:108]]\n",
    "        self.midprice = float(data[108])\n",
    "        self.uptime = data[109]\n",
    "        self.lastprice = float(data[111])\n",
    "        self.volume = float(data[112])\n",
    "        self.lastvolume = float(data[113])\n",
    "        self.turnover = float(data[114])\n",
    "        self.lastturnover = float(data[115])\n",
    "        self.askprice = [float(data[120]), float(data[119]), float(data[118]), float(data[117]), float(data[116])]\n",
    "        self.bidprice = [float(data[121]), float(data[122]), float(data[123]), float(data[124]), float(data[125])]\n",
    "        self.askvolume = [float(data[130]), float(data[129]), float(data[128]), float(data[127]), float(data[126])]\n",
    "        self.bibdvolume = [float(data[131]), float(data[132]), float(data[133]), float(data[134]), float(data[135])]\n",
    "        self.openinterest = float(data[136])\n",
    "        self.upper = float(data[137])\n",
    "        self.lower = float(data[138])\n",
    "        self.day = 0\n",
    "        self.apm = ''\n",
    "\n",
    "        self.init_time()\n",
    "\n",
    "    def get_feature_vector(self):\n",
    "        return np.array(self.fv)\n",
    "\n",
    "    def init_time(self):\n",
    "        \"\"\"\n",
    "        Init time of the single line data\n",
    "\n",
    "        \"\"\"\n",
    "        time_digit = self.uptime\n",
    "        param = time_digit.split(':')\n",
    "        h = int(param[0])\n",
    "        m = int(param[1])\n",
    "        s = int(param[2])\n",
    "        self.uptime = datetime.time(h, m, s)\n",
    "        if self.uptime > datetime.time(12,0,0):\n",
    "            self.apm = 'pm'\n",
    "        else:\n",
    "            self.apm = 'am'\n",
    "\n",
    "\n",
    "def get_fromcsv(root):\n",
    "    \"\"\"\n",
    "    Reading the data from csv simutaniously wash out the data that across two days\n",
    "\n",
    "    \"\"\"\n",
    "    flag = False\n",
    "    dataset = []\n",
    "    begin = time.time()\n",
    "    last_time = datetime.time(0,0,0)\n",
    "    day_count = 0\n",
    "    global TMP\n",
    "    with open(root, 'r') as f:\n",
    "        datafile = csv.reader(f)\n",
    "        for line in datafile:\n",
    "            if flag:\n",
    "                TMP = line\n",
    "                data = Data(line)\n",
    "                dataset.append(data)\n",
    "                if data.uptime < last_time:\n",
    "                    day_count += 1\n",
    "                    data.day = day_count\n",
    "                    #print(data.day)\n",
    "\n",
    "                # if day_count == 3:\n",
    "                #     break\n",
    "\n",
    "                last_time = data.uptime\n",
    "            else:\n",
    "                flag = True\n",
    "    end = time.time()\n",
    "    print('dataset length:\\t{}\\ttime:\\t{}'.format(len(dataset), end - begin))\n",
    "    return dataset\n",
    "\n",
    "def merge_data(simdatas):\n",
    "    newdata = Data(TMP)\n",
    "    l = len(simdatas)\n",
    "    new_fv = [0 for i in range(108)]\n",
    "    new_midprice = 0\n",
    "    new_lastvolume = 0\n",
    "    new_lastturnover = 0\n",
    "    new_askprice = [0 for i in range(5)]\n",
    "    new_bidprice = [0 for i in range(5)]\n",
    "    new_askvolume = [0 for i in range(5)]\n",
    "    new_bidvolume = [0 for i in range(5)]\n",
    "    lastdata = simdatas[-1]\n",
    "    for data in simdatas:\n",
    "        for i in range(108):\n",
    "            new_fv[i] += data.fv[i]\n",
    "        new_midprice += data.midprice\n",
    "        new_lastvolume += data.lastvolume\n",
    "        new_lastturnover += data.lastturnover\n",
    "        for i in range(5):\n",
    "            new_askprice[i] += data.askprice[i]\n",
    "            new_bidprice[i] += data.bidprice[i]\n",
    "            new_askvolume[i] += data.askvolume[i]\n",
    "            new_bidvolume[i] += data.bibdvolume[i]\n",
    "\n",
    "    for i in range(108):\n",
    "        new_fv[i] /= l\n",
    "\n",
    "    new_midprice /= l\n",
    "    new_lastvolume /= l\n",
    "    new_lastturnover /= l\n",
    "\n",
    "    for i in range(5):\n",
    "        new_askprice[i] /= l\n",
    "        new_bidprice[i] /= l\n",
    "        new_askvolume[i] /= l\n",
    "        new_bidvolume[i] /= l\n",
    "\n",
    "    newdata.fv = new_fv\n",
    "    newdata.midprice = new_midprice\n",
    "    newdata.uptime = lastdata.uptime\n",
    "    newdata.lastprice = lastdata.lastprice\n",
    "    newdata.volume = lastdata.volume\n",
    "    newdata.lastvolume = new_lastvolume\n",
    "    newdata.turnover = lastdata.turnover\n",
    "    newdata.lastturnover = new_lastturnover\n",
    "    newdata.askprice = new_askprice\n",
    "    newdata.bidprice = new_bidprice\n",
    "    newdata.askvolume = new_askvolume\n",
    "    newdata.bibdvolume = new_bidvolume\n",
    "    newdata.openinterest = lastdata.openinterest\n",
    "    newdata.upper = lastdata.upper\n",
    "    newdata.lower = lastdata.lower\n",
    "    newdata.day = lastdata.day\n",
    "    newdata.apm = lastdata.apm\n",
    "\n",
    "    return newdata\n",
    "\n",
    "def clean_data(dataset):\n",
    "    \"\"\"\n",
    "    Wash out the data that is at the same time\n",
    "\n",
    "    \"\"\"\n",
    "    last_time = dataset[0].uptime\n",
    "    simdatas = []\n",
    "    new_dataset = []\n",
    "    for data in dataset:\n",
    "        if data.uptime == last_time:\n",
    "            simdatas.append(data)\n",
    "        else:\n",
    "            new_dataset.append(merge_data(simdatas))\n",
    "            simdatas = [data]\n",
    "            last_time = data.uptime\n",
    "\n",
    "    if len(simdatas) > 0:\n",
    "        new_dataset.append(merge_data(simdatas))\n",
    "\n",
    "    return new_dataset\n",
    "\n",
    "def get_raw_label(new_dataset, n, seq_len, sample_gap):\n",
    "    data_day_order = []\n",
    "    tmp = []\n",
    "    apm = 'am'\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for data in new_dataset:\n",
    "        if data.apm == apm:\n",
    "            tmp.append(data)\n",
    "        else:\n",
    "            data_day_order.append(tmp)\n",
    "            tmp = [data]\n",
    "            apm = 'pm' if apm == 'am' else 'am'\n",
    "\n",
    "    for i, data_batch in enumerate(data_day_order):\n",
    "        data_day_order[i] = data_batch[:-1 * n]\n",
    "        sample_num = (len(data_day_order[i]) // sample_gap) - 1\n",
    "        for j in range(sample_num):\n",
    "            left = j * sample_gap\n",
    "            mid = left + seq_len\n",
    "            right = left + seq_len + n\n",
    "            tmp = []\n",
    "            for k in range(left, mid):\n",
    "                tmp.append(data_day_order[i][k].midprice)\n",
    "                tmp.append(data_day_order[i][k].uptime)\n",
    "                tmp.append(data_day_order[i][k].lastprice)\n",
    "                tmp.append(data_day_order[i][k].volume)\n",
    "                tmp.append(data_day_order[i][k].lastvolume)\n",
    "                tmp.append(data_day_order[i][k].turnover)\n",
    "                tmp.append(data_day_order[i][k].lastturnover)\n",
    "                tmp.append(data_day_order[i][k].upper)\n",
    "                tmp.append(data_day_order[i][k].lower)\n",
    "                tmp.extend(data_day_order[i][k].askprice)\n",
    "                tmp.extend(data_day_order[i][k].bidprice)\n",
    "                tmp.extend(data_day_order[i][k].askvolume)\n",
    "                tmp.extend(data_day_order[i][k].bibdvolume)\n",
    "            dataset.append(tmp)\n",
    "            current = data_day_order[i][mid - 1].askprice[0] + data_day_order[i][mid - 1].bidprice[0]\n",
    "            future = data_day_order[i][right - 1].askprice[0] + data_day_order[i][right - 1].bidprice[0]\n",
    "            label = (future - current) / 2\n",
    "            labels.append(label)\n",
    "\n",
    "    print('total data:\\t{}\\ttotal labels:\\t{}'.format(len(dataset), len(labels)))\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "def get_indicator_label(new_dataset, n, seq_len, sample_gap):\n",
    "    data_day_order = []\n",
    "    tmp = []\n",
    "    apm = 'am'\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for data in new_dataset:\n",
    "        if data.apm == apm:\n",
    "            tmp.append(data)\n",
    "        else:\n",
    "            data_day_order.append(tmp)\n",
    "            tmp = [data]\n",
    "            apm = 'pm' if apm == 'am' else 'am'\n",
    "\n",
    "    for i, data_batch in enumerate(data_day_order):\n",
    "        data_day_order[i] = data_batch[:-1 * n]\n",
    "        sample_num = (len(data_day_order[i]) // sample_gap) - 1\n",
    "        for j in range(sample_num):\n",
    "            left = j * sample_gap\n",
    "            mid = left + seq_len\n",
    "            right = left + seq_len + n\n",
    "            tmp = []\n",
    "            for k in range(left, mid):\n",
    "                tmp.append(data_day_order[i][k].fv)\n",
    "            dataset.append(tmp)\n",
    "            current = data_day_order[i][mid - 1].askprice[0] + data_day_order[i][mid - 1].bidprice[0]\n",
    "            future = data_day_order[i][right - 1].askprice[0] + data_day_order[i][right - 1].bidprice[0]\n",
    "            label = (future - current) / 2\n",
    "            labels.append(label)\n",
    "\n",
    "    print('total data:\\t{}\\ttotal labels:\\t{}'.format(len(dataset), len(labels)))\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "def divid_dataset(dataset, labels):\n",
    "    \"\"\"\n",
    "    Divide the dataset into train, validation & test\n",
    "\n",
    "    \"\"\"\n",
    "    l = len(dataset)\n",
    "    idx_list = list(range(l))\n",
    "    random.shuffle(idx_list)\n",
    "\n",
    "    train_range = int(l * 0.8)\n",
    "    dev_range = int(l * 0.9)\n",
    "\n",
    "    train_input = []\n",
    "    train_label = []\n",
    "    dev_input = []\n",
    "    dev_label = []\n",
    "    test_input = []\n",
    "    test_label = []\n",
    "\n",
    "    for i in range(train_range):\n",
    "        idx = idx_list[i]\n",
    "        train_input.append(dataset[idx])\n",
    "        train_label.append(labels[idx])\n",
    "\n",
    "    for i in range(train_range, dev_range):\n",
    "        idx = idx_list[i]\n",
    "        dev_input.append(dataset[idx])\n",
    "        dev_label.append(labels[idx])\n",
    "\n",
    "    for i in range(dev_range, l):\n",
    "        idx = idx_list[i]\n",
    "        test_input.append(dataset[idx])\n",
    "        test_label.append(labels[idx])\n",
    "\n",
    "    print('train set size:\\t{}\\tdevelop set size:\\t{}\\ttest set size:\\t{}'.format(len(train_input), len(dev_input), len(test_input)))\n",
    "\n",
    "    return (train_input, train_label), (dev_input, dev_label), (test_input, test_label)\n",
    "\n",
    "def DataLoader(root, N, seq_len, sample_gap, type=True, dev_bs = 1, test_bs = 1):\n",
    "    \"\"\"\n",
    "    root : the place of the csv file\n",
    "    N : the n-th future prediction\n",
    "    seq_len : the n future data used to predict the result\n",
    "    sample_gap : stride of the data using\n",
    "\n",
    "    \"\"\"\n",
    "    dataset = get_fromcsv(root)\n",
    "    dataset = clean_data(dataset)\n",
    "    print(np.array(dataset).shape)\n",
    "    if type:\n",
    "        dataset, labels = get_indicator_label(dataset, N, seq_len, sample_gap)\n",
    "    else:\n",
    "        dataset, labels = get_raw_label(dataset, N, seq_len, sample_gap)\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = divid_dataset(dataset, labels)\n",
    "\n",
    "    return (np.array(train_input), np.array(train_label)), (np.array(dev_input), np.array(dev_label)), (np.array(test_input), np.array(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Different Methods to do regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length:\t1721577\ttime:\t288.38901805877686\n",
      "(576093,)\n",
      "total data:\t18864\ttotal labels:\t18864\n",
      "train set size:\t15091\tdevelop set size:\t1886\ttest set size:\t1887\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 34, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 9, 12, 64)         36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                15370     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 80,949\n",
      "Trainable params: 80,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 52s 3ms/step - loss: 2.3231 - val_loss: 2.1748\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 51s 3ms/step - loss: 2.2503 - val_loss: 2.1613\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 46s 3ms/step - loss: 2.2500 - val_loss: 2.1622\n",
      "1.4916362299640091\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "seq_len = 30\n",
    "sample_gap = 30\n",
    "\n",
    "if os.path.exists(path=\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "\n",
    "\"\"\"\n",
    "Train input shape N_samples * seq_len * 108\n",
    "Train label shape N_samples * 1\n",
    "\n",
    "\"\"\"\n",
    "def CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    train_input = train_input.reshape(train_input.shape[0], train_input.shape[1], int(train_input.shape[2] / 3), 3)\n",
    "    test_input = test_input.reshape(test_input.shape[0], test_input.shape[1], int(test_input.shape[2] / 3), 3)\n",
    "    dev_input = dev_input.reshape(dev_input.shape[0], dev_input.shape[1], int(dev_input.shape[2] / 3), 3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid', input_shape=(train_input.shape[1], train_input.shape[2], train_input.shape[3])))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    CNNIndicatorPred = model.predict(test_input)\n",
    "    CNNacc = np.std(CNNIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return CNNacc\n",
    "CNNacc = CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(CNNacc)\n",
    "# print(pred.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5704781815193638\n"
     ]
    }
   ],
   "source": [
    "def AdaRegress(X, y, n_estimators, random_st):\n",
    "    regr = AdaBoostRegressor(n_estimators=n_estimators, random_state=random_st)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "if os.path.exists(path=\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "\n",
    "pca = PCA(n_components=540)\n",
    "train_input = train_input.reshape(train_input.shape[0], -1)\n",
    "dev_input = dev_input.reshape(dev_input.shape[0], -1)\n",
    "test_input = test_input.reshape(test_input.shape[0], -1)\n",
    "train_input = pca.fit_transform(train_input)\n",
    "dev_input = pca.fit_transform(dev_input)\n",
    "test_input = pca.fit_transform(test_input)\n",
    "\n",
    "regressor = AdaRegress(train_input, np.array(train_label), 100, 0)\n",
    "\n",
    "AdaIndicatorPred = regressor.predict(test_input)\n",
    "AdaBoostacc = np.std(AdaIndicatorPred - np.array(test_label))\n",
    "print(AdaBoostacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 128)               69248     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 73,649\n",
      "Trainable params: 73,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9012 samples, validate on 1127 samples\n",
      "Epoch 1/3\n",
      "9012/9012 [==============================] - 4s 393us/step - loss: 2.1940 - val_loss: 3.1879\n",
      "Epoch 2/3\n",
      "9012/9012 [==============================] - 1s 114us/step - loss: 2.1442 - val_loss: 4.1296\n",
      "Epoch 3/3\n",
      "9012/9012 [==============================] - 1s 113us/step - loss: 2.1480 - val_loss: 3.6183\n",
      "Epoch 00003: early stopping\n",
      "1.5465264107079268\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(train_input.shape[1], ), kernel_initializer='uniform', activation='sigmoid', kernel_regularizer=keras.regularizers.l1(0.)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "DNNIndicatorPred = model.predict(test_input)\n",
    "DNNacc = np.std(DNNIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "print(DNNacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5416751363111998\n"
     ]
    }
   ],
   "source": [
    "def GBDTRegress(X, y, depth, random_st):\n",
    "    regr = GradientBoostingRegressor(max_depth=depth, random_state=random_st)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "regressor = GBDTRegress(train_input, np.array(train_label), 2, 0)\n",
    "\n",
    "GBDTIndicatorPred = regressor.predict(test_input)\n",
    "GBDTacc = np.std(GBDTIndicatorPred - np.array(test_label))\n",
    "print(GBDTacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5328322535703058\n"
     ]
    }
   ],
   "source": [
    "def RandomForestRegress(X, y, depth, random_st, n_estimators):\n",
    "    regr = RandomForestRegressor(max_depth=depth, random_state=random_st, n_estimators=n_estimators)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "regressor = RandomForestRegress(train_input, np.array(train_label), 2, 0, 100)\n",
    "\n",
    "RFIndicatorPred = regressor.predict(test_input)\n",
    "RFacc = np.std(RFIndicatorPred - np.array(test_label))\n",
    "print(RFacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:19: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(50, 108), return_sequences=True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9012 samples, validate on 1127 samples\n",
      "Epoch 1/3\n",
      "9012/9012 [==============================] - 35s 4ms/step - loss: 2.1555 - val_loss: 2.7627\n",
      "Epoch 2/3\n",
      "9012/9012 [==============================] - 33s 4ms/step - loss: 2.1317 - val_loss: 2.7666\n",
      "Epoch 3/3\n",
      "9012/9012 [==============================] - 34s 4ms/step - loss: 2.1323 - val_loss: 2.7609\n",
      "Epoch 00003: early stopping\n",
      "1.537528631611567\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path=\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "\n",
    "\"\"\"\n",
    "Train input shape N_samples * seq_len * 108\n",
    "Train label shape N_samples * 1\n",
    "\n",
    "\"\"\"\n",
    "def LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_length=train_input.shape[1], input_dim=train_input.shape[2], return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    LSTMIndicatorPred = model.predict(test_input)\n",
    "    LSTMacc = np.std(LSTMIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return LSTMacc\n",
    "LSTMacc = LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(LSTMacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6783490146996896\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path=\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap, False)\n",
    "    with open(\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "        \n",
    "print(train_input.shape)\n",
    "train_input = train_input.reshape(train_input.shape[0], -1)\n",
    "dev_input = dev_input.reshape(dev_input.shape[0], -1)\n",
    "test_input = test_input.reshape(test_input.shape[0], -1)\n",
    "# train_input = pca.fit_transform(train_input)\n",
    "# dev_input = pca.fit_transform(dev_input)\n",
    "# test_input = pca.fit_transform(test_input)\n",
    "\n",
    "regressor = AdaRegress(train_input, np.array(train_label), 100, 0)\n",
    "\n",
    "AdaRawPred = regressor.predict(test_input)\n",
    "AdaBoostacc2 = np.std(AdaRawPred - np.array(test_label))\n",
    "print(AdaBoostacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_37 (Dense)             (None, 128)               691328    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 695,729\n",
      "Trainable params: 695,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9012 samples, validate on 1127 samples\n",
      "Epoch 1/3\n",
      "9012/9012 [==============================] - 6s 618us/step - loss: 2.3334 - val_loss: 2.4463\n",
      "Epoch 2/3\n",
      "9012/9012 [==============================] - 3s 360us/step - loss: 2.1794 - val_loss: 2.4093\n",
      "Epoch 3/3\n",
      "9012/9012 [==============================] - 3s 356us/step - loss: 2.1650 - val_loss: 2.4283\n",
      "1.6465977725264755\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(train_input.shape[1], ), kernel_initializer='uniform', activation='sigmoid', kernel_regularizer=keras.regularizers.l1(0.)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "DNNRawPred = model.predict(test_input)\n",
    "DNNacc2 = np.std(DNNRawPred - test_label.reshape(test_label.shape[0], 1))\n",
    "print(DNNacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6412394080028718\n"
     ]
    }
   ],
   "source": [
    "regressor = GBDTRegress(train_input, np.array(train_label), 2, 0)\n",
    "\n",
    "GBDTRawPred = regressor.predict(test_input)\n",
    "GBDTacc2 = np.std(GBDTRawPred - np.array(test_label))\n",
    "print(GBDTacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6199134532344999\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegress(train_input, np.array(train_label), 2, 0, 100)\n",
    "\n",
    "RFRawPred = regressor.predict(test_input)\n",
    "RFacc2 = np.std(RFRawPred - np.array(test_label))\n",
    "print(RFacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9012, 50, 108)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:19: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(50, 108), return_sequences=True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_19 (LSTM)               (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_20 (LSTM)               (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9012 samples, validate on 1127 samples\n",
      "Epoch 1/3\n",
      "9012/9012 [==============================] - 32s 4ms/step - loss: 2.1586 - val_loss: 2.3469\n",
      "Epoch 2/3\n",
      "9012/9012 [==============================] - 29s 3ms/step - loss: 2.1413 - val_loss: 2.3586\n",
      "Epoch 3/3\n",
      "9012/9012 [==============================] - 29s 3ms/step - loss: 2.1388 - val_loss: 2.3532\n",
      "1.6420239050048966\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path=\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "    with open(\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "\n",
    "print(train_input.shape)\n",
    "\"\"\"\n",
    "Train input shape N_samples * seq_len * 108\n",
    "Train label shape N_samples * 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "LSTMacc2 = LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(LSTMacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_13 (Conv2D)           (None, 48, 34, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 46, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 23, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 21, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 19, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 9, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 10)                34570     \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 100,149\n",
      "Trainable params: 100,149\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9012 samples, validate on 1127 samples\n",
      "Epoch 1/3\n",
      "9012/9012 [==============================] - 59s 7ms/step - loss: 2.4568 - val_loss: 2.3645\n",
      "Epoch 2/3\n",
      "9012/9012 [==============================] - 56s 6ms/step - loss: 2.1383 - val_loss: 2.3591\n",
      "Epoch 3/3\n",
      "9012/9012 [==============================] - 56s 6ms/step - loss: 2.1376 - val_loss: 2.3389\n",
      "1.6406177202536136\n"
     ]
    }
   ],
   "source": [
    "CNNacc2 = CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(CNNacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15cde1240>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(['DNN', 'CNN', 'LSTM', 'GBDT', 'RandomForest', 'AdaBoost'], [DNNacc, CNNacc, LSTMacc, GBDTacc, RFacc, AdaBoostacc], 'red', label='indicator')\n",
    "plt.plot(['DNN', 'CNN', 'LSTM', 'GBDT', 'RandomForest', 'AdaBoost'], [DNNacc2, CNNacc2, LSTMacc2, GBDTacc2, RFacc2, AdaBoostacc2], 'blue', label='raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Different N & Sample Gaps\n",
    "Using LSTM model as an example, we can show the different accuracy or say, MSE loss by choosing distinct value of n & sample gaps & sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(50, 108), return_sequences=True)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9012 samples, validate on 1127 samples\n",
      "Epoch 1/3\n",
      "9012/9012 [==============================] - 32s 4ms/step - loss: 2.1649 - val_loss: 2.7724\n",
      "Epoch 2/3\n",
      "9012/9012 [==============================] - 29s 3ms/step - loss: 2.1365 - val_loss: 2.7695\n",
      "Epoch 3/3\n",
      "9012/9012 [==============================] - 33s 4ms/step - loss: 2.1282 - val_loss: 2.7560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(100, 108), return_sequences=True)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100, 128)          121344    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4452 samples, validate on 556 samples\n",
      "Epoch 1/3\n",
      "4452/4452 [==============================] - 33s 7ms/step - loss: 2.1655 - val_loss: 2.4160\n",
      "Epoch 2/3\n",
      "4452/4452 [==============================] - 33s 7ms/step - loss: 2.1391 - val_loss: 2.3849\n",
      "Epoch 3/3\n",
      "4452/4452 [==============================] - 33s 7ms/step - loss: 2.1189 - val_loss: 2.4428\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8957 samples, validate on 1120 samples\n",
      "Epoch 1/3\n",
      "8957/8957 [==============================] - 32s 4ms/step - loss: 11.2796 - val_loss: 10.3049\n",
      "Epoch 2/3\n",
      "8957/8957 [==============================] - 30s 3ms/step - loss: 11.2122 - val_loss: 10.2877\n",
      "Epoch 3/3\n",
      "8957/8957 [==============================] - 32s 4ms/step - loss: 11.2082 - val_loss: 10.2989\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4424 samples, validate on 553 samples\n",
      "Epoch 1/3\n",
      "4424/4424 [==============================] - 17s 4ms/step - loss: 11.6457 - val_loss: 10.1186\n",
      "Epoch 2/3\n",
      "4424/4424 [==============================] - 14s 3ms/step - loss: 11.5284 - val_loss: 9.9799\n",
      "Epoch 3/3\n",
      "4424/4424 [==============================] - 14s 3ms/step - loss: 11.5431 - val_loss: 9.9474\n",
      "Epoch 00003: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4391 samples, validate on 549 samples\n",
      "Epoch 1/3\n",
      "4391/4391 [==============================] - 17s 4ms/step - loss: 22.9083 - val_loss: 25.1255\n",
      "Epoch 2/3\n",
      "4391/4391 [==============================] - 15s 3ms/step - loss: 22.7617 - val_loss: 25.0318\n",
      "Epoch 3/3\n",
      "4391/4391 [==============================] - 15s 3ms/step - loss: 22.7281 - val_loss: 25.2659\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 100, 128)          121344    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4391 samples, validate on 549 samples\n",
      "Epoch 1/3\n",
      "4391/4391 [==============================] - 36s 8ms/step - loss: 23.4998 - val_loss: 19.9841\n",
      "Epoch 2/3\n",
      "4391/4391 [==============================] - 31s 7ms/step - loss: 23.3116 - val_loss: 20.0874\n",
      "Epoch 3/3\n",
      "4391/4391 [==============================] - 32s 7ms/step - loss: 23.2722 - val_loss: 20.0427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13c86cc18>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_length=train_input.shape[1], input_dim=train_input.shape[2], return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    LSTMIndicatorPred = model.predict(test_input)\n",
    "    LSTMacc = np.std(LSTMIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return LSTMacc\n",
    "\n",
    "NSS = [[10, 50, 50], [10, 100, 100], [50, 50, 50], [50, 50, 100], [100, 50, 100], [100, 100, 100]]\n",
    "accs = []\n",
    "for nss in NSS:\n",
    "    N, seq_len, sample_gap = nss\n",
    "    if os.path.exists(path=\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "        with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "            (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "    else:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "        with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "            data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "            pickle.dump(data_list, save_data)\n",
    "    \n",
    "    LSTMacc = LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "    accs.append(LSTMacc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13c8fc6d8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot([\"10 50 50\", \"10 100 100\", \"50 50 50\", \"50 50 100\", \"100 50 100\", \"100 100 100\"], accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
