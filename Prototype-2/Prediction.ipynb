{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Predicting\n",
    "We have used several methods to implement the prediction. The data are seperated into 2 parts where the first part is about the indicators and the second part is about the raw data. The raw data will be used by feature tools later to generate some amazing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv, datetime, time, random\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from data_reader import DataLoader\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
    "import os, pickle\n",
    "from data_reader import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP = ''\n",
    "\n",
    "class Data():\n",
    "    \"\"\"\n",
    "    Loading a single line of the data\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.fv = [float(d) for d in data[:108]]\n",
    "        self.midprice = float(data[108])\n",
    "        self.uptime = data[109]\n",
    "        self.lastprice = float(data[111])\n",
    "        self.volume = float(data[112])\n",
    "        self.lastvolume = float(data[113])\n",
    "        self.turnover = float(data[114])\n",
    "        self.lastturnover = float(data[115])\n",
    "        self.askprice = [float(data[120]), float(data[119]), float(data[118]), float(data[117]), float(data[116])]\n",
    "        self.bidprice = [float(data[121]), float(data[122]), float(data[123]), float(data[124]), float(data[125])]\n",
    "        self.askvolume = [float(data[130]), float(data[129]), float(data[128]), float(data[127]), float(data[126])]\n",
    "        self.bibdvolume = [float(data[131]), float(data[132]), float(data[133]), float(data[134]), float(data[135])]\n",
    "        self.openinterest = float(data[136])\n",
    "        self.upper = float(data[137])\n",
    "        self.lower = float(data[138])\n",
    "        self.day = 0\n",
    "        self.apm = ''\n",
    "\n",
    "        self.init_time()\n",
    "\n",
    "    def get_feature_vector(self):\n",
    "        return np.array(self.fv)\n",
    "\n",
    "    def init_time(self):\n",
    "        \"\"\"\n",
    "        Init time of the single line data\n",
    "\n",
    "        \"\"\"\n",
    "        time_digit = self.uptime\n",
    "        param = time_digit.split(':')\n",
    "        h = int(param[0])\n",
    "        m = int(param[1])\n",
    "        s = int(param[2])\n",
    "        self.uptime = datetime.time(h, m, s)\n",
    "        if self.uptime > datetime.time(12,0,0):\n",
    "            self.apm = 'pm'\n",
    "        else:\n",
    "            self.apm = 'am'\n",
    "\n",
    "\n",
    "def get_fromcsv(root):\n",
    "    \"\"\"\n",
    "    Reading the data from csv simutaniously wash out the data that across two days\n",
    "\n",
    "    \"\"\"\n",
    "    flag = False\n",
    "    dataset = []\n",
    "    begin = time.time()\n",
    "    last_time = datetime.time(0,0,0)\n",
    "    day_count = 0\n",
    "    global TMP\n",
    "    with open(root, 'r') as f:\n",
    "        datafile = csv.reader(f)\n",
    "        for line in datafile:\n",
    "            if flag:\n",
    "                TMP = line\n",
    "                data = Data(line)\n",
    "                dataset.append(data)\n",
    "                if data.uptime < last_time:\n",
    "                    day_count += 1\n",
    "                    data.day = day_count\n",
    "                    #print(data.day)\n",
    "\n",
    "                # if day_count == 3:\n",
    "                #     break\n",
    "\n",
    "                last_time = data.uptime\n",
    "            else:\n",
    "                flag = True\n",
    "    end = time.time()\n",
    "    print('dataset length:\\t{}\\ttime:\\t{}'.format(len(dataset), end - begin))\n",
    "    return dataset\n",
    "\n",
    "def merge_data(simdatas):\n",
    "    newdata = Data(TMP)\n",
    "    l = len(simdatas)\n",
    "    new_fv = [0 for i in range(108)]\n",
    "    new_midprice = 0\n",
    "    new_lastvolume = 0\n",
    "    new_lastturnover = 0\n",
    "    new_askprice = [0 for i in range(5)]\n",
    "    new_bidprice = [0 for i in range(5)]\n",
    "    new_askvolume = [0 for i in range(5)]\n",
    "    new_bidvolume = [0 for i in range(5)]\n",
    "    lastdata = simdatas[-1]\n",
    "    for data in simdatas:\n",
    "        for i in range(108):\n",
    "            new_fv[i] += data.fv[i]\n",
    "        new_midprice += data.midprice\n",
    "        new_lastvolume += data.lastvolume\n",
    "        new_lastturnover += data.lastturnover\n",
    "        for i in range(5):\n",
    "            new_askprice[i] += data.askprice[i]\n",
    "            new_bidprice[i] += data.bidprice[i]\n",
    "            new_askvolume[i] += data.askvolume[i]\n",
    "            new_bidvolume[i] += data.bibdvolume[i]\n",
    "\n",
    "    for i in range(108):\n",
    "        new_fv[i] /= l\n",
    "\n",
    "    new_midprice /= l\n",
    "    new_lastvolume /= l\n",
    "    new_lastturnover /= l\n",
    "\n",
    "    for i in range(5):\n",
    "        new_askprice[i] /= l\n",
    "        new_bidprice[i] /= l\n",
    "        new_askvolume[i] /= l\n",
    "        new_bidvolume[i] /= l\n",
    "\n",
    "    newdata.fv = new_fv\n",
    "    newdata.midprice = new_midprice\n",
    "    newdata.uptime = lastdata.uptime\n",
    "    newdata.lastprice = lastdata.lastprice\n",
    "    newdata.volume = lastdata.volume\n",
    "    newdata.lastvolume = new_lastvolume\n",
    "    newdata.turnover = lastdata.turnover\n",
    "    newdata.lastturnover = new_lastturnover\n",
    "    newdata.askprice = new_askprice\n",
    "    newdata.bidprice = new_bidprice\n",
    "    newdata.askvolume = new_askvolume\n",
    "    newdata.bibdvolume = new_bidvolume\n",
    "    newdata.openinterest = lastdata.openinterest\n",
    "    newdata.upper = lastdata.upper\n",
    "    newdata.lower = lastdata.lower\n",
    "    newdata.day = lastdata.day\n",
    "    newdata.apm = lastdata.apm\n",
    "\n",
    "    return newdata\n",
    "\n",
    "def clean_data(dataset):\n",
    "    \"\"\"\n",
    "    Wash out the data that is at the same time\n",
    "\n",
    "    \"\"\"\n",
    "    last_time = dataset[0].uptime\n",
    "    simdatas = []\n",
    "    new_dataset = []\n",
    "    for data in dataset:\n",
    "        if data.uptime == last_time:\n",
    "            simdatas.append(data)\n",
    "        else:\n",
    "            new_dataset.append(merge_data(simdatas))\n",
    "            simdatas = [data]\n",
    "            last_time = data.uptime\n",
    "\n",
    "    if len(simdatas) > 0:\n",
    "        new_dataset.append(merge_data(simdatas))\n",
    "\n",
    "    return new_dataset\n",
    "\n",
    "def get_raw_label(new_dataset, n, seq_len, sample_gap):\n",
    "    data_day_order = []\n",
    "    tmp = []\n",
    "    apm = 'am'\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for data in new_dataset:\n",
    "        if data.apm == apm:\n",
    "            tmp.append(data)\n",
    "        else:\n",
    "            data_day_order.append(tmp)\n",
    "            tmp = [data]\n",
    "            apm = 'pm' if apm == 'am' else 'am'\n",
    "\n",
    "    for i, data_batch in enumerate(data_day_order):\n",
    "        data_day_order[i] = data_batch[:-1 * n]\n",
    "        sample_num = (len(data_day_order[i]) // sample_gap) - 1\n",
    "        for j in range(sample_num):\n",
    "            left = j * sample_gap\n",
    "            mid = left + seq_len\n",
    "            right = left + seq_len + n\n",
    "            tmp = []\n",
    "            for k in range(left, mid):\n",
    "                tmp.append(data_day_order[i][k].midprice)\n",
    "                tmp.append(data_day_order[i][k].lastprice)\n",
    "                tmp.append(data_day_order[i][k].volume)\n",
    "                tmp.append(data_day_order[i][k].lastvolume)\n",
    "                tmp.append(data_day_order[i][k].turnover)\n",
    "                tmp.append(data_day_order[i][k].lastturnover)\n",
    "                tmp.append(data_day_order[i][k].upper)\n",
    "                tmp.append(data_day_order[i][k].lower)\n",
    "                tmp.extend(data_day_order[i][k].askprice)\n",
    "                tmp.extend(data_day_order[i][k].bidprice)\n",
    "                tmp.extend(data_day_order[i][k].askvolume)\n",
    "                tmp.extend(data_day_order[i][k].bibdvolume)\n",
    "            dataset.append(tmp)\n",
    "            current = data_day_order[i][mid - 1].askprice[0] + data_day_order[i][mid - 1].bidprice[0]\n",
    "            future = data_day_order[i][right - 1].askprice[0] + data_day_order[i][right - 1].bidprice[0]\n",
    "            label = (future - current) / 2\n",
    "            labels.append(label)\n",
    "\n",
    "    print('total data:\\t{}\\ttotal labels:\\t{}'.format(len(dataset), len(labels)))\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "def get_indicator_label(new_dataset, n, seq_len, sample_gap):\n",
    "    data_day_order = []\n",
    "    tmp = []\n",
    "    apm = 'am'\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    for data in new_dataset:\n",
    "        if data.apm == apm:\n",
    "            tmp.append(data)\n",
    "        else:\n",
    "            data_day_order.append(tmp)\n",
    "            tmp = [data]\n",
    "            apm = 'pm' if apm == 'am' else 'am'\n",
    "\n",
    "    for i, data_batch in enumerate(data_day_order):\n",
    "        data_day_order[i] = data_batch[:-1 * n]\n",
    "        sample_num = (len(data_day_order[i]) // sample_gap) - 1\n",
    "        for j in range(sample_num):\n",
    "            left = j * sample_gap\n",
    "            mid = left + seq_len\n",
    "            right = left + seq_len + n\n",
    "            tmp = []\n",
    "            for k in range(left, mid):\n",
    "                tmp.append(data_day_order[i][k].fv)\n",
    "            dataset.append(tmp)\n",
    "            current = data_day_order[i][mid - 1].askprice[0] + data_day_order[i][mid - 1].bidprice[0]\n",
    "            future = data_day_order[i][right - 1].askprice[0] + data_day_order[i][right - 1].bidprice[0]\n",
    "            label = (future - current) / 2\n",
    "            labels.append(label)\n",
    "\n",
    "    print('total data:\\t{}\\ttotal labels:\\t{}'.format(len(dataset), len(labels)))\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "def divid_dataset(dataset, labels):\n",
    "    \"\"\"\n",
    "    Divide the dataset into train, validation & test\n",
    "\n",
    "    \"\"\"\n",
    "    l = len(dataset)\n",
    "    idx_list = list(range(l))\n",
    "    random.shuffle(idx_list)\n",
    "\n",
    "    train_range = int(l * 0.8)\n",
    "    dev_range = int(l * 0.9)\n",
    "\n",
    "    train_input = []\n",
    "    train_label = []\n",
    "    dev_input = []\n",
    "    dev_label = []\n",
    "    test_input = []\n",
    "    test_label = []\n",
    "\n",
    "    for i in range(train_range):\n",
    "        idx = idx_list[i]\n",
    "        train_input.append(dataset[idx])\n",
    "        train_label.append(labels[idx])\n",
    "\n",
    "    for i in range(train_range, dev_range):\n",
    "        idx = idx_list[i]\n",
    "        dev_input.append(dataset[idx])\n",
    "        dev_label.append(labels[idx])\n",
    "\n",
    "    for i in range(dev_range, l):\n",
    "        idx = idx_list[i]\n",
    "        test_input.append(dataset[idx])\n",
    "        test_label.append(labels[idx])\n",
    "\n",
    "    print('train set size:\\t{}\\tdevelop set size:\\t{}\\ttest set size:\\t{}'.format(len(train_input), len(dev_input), len(test_input)))\n",
    "\n",
    "    return (train_input, train_label), (dev_input, dev_label), (test_input, test_label)\n",
    "\n",
    "def DataLoader(root, N, seq_len, sample_gap, type=True, dev_bs = 1, test_bs = 1):\n",
    "    \"\"\"\n",
    "    root : the place of the csv file\n",
    "    N : the n-th future prediction\n",
    "    seq_len : the n future data used to predict the result\n",
    "    sample_gap : stride of the data using\n",
    "\n",
    "    \"\"\"\n",
    "    dataset = get_fromcsv(root)\n",
    "    dataset = clean_data(dataset)\n",
    "    print(np.array(dataset).shape)\n",
    "    if type:\n",
    "        dataset, labels = get_indicator_label(dataset, N, seq_len, sample_gap)\n",
    "    else:\n",
    "        dataset, labels = get_raw_label(dataset, N, seq_len, sample_gap)\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = divid_dataset(dataset, labels)\n",
    "\n",
    "    return (np.array(train_input), np.array(train_label)), (np.array(dev_input), np.array(dev_label)), (np.array(test_input), np.array(test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Different Methods to do regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length:\t1721577\ttime:\t288.38901805877686\n",
      "(576093,)\n",
      "total data:\t18864\ttotal labels:\t18864\n",
      "train set size:\t15091\tdevelop set size:\t1886\ttest set size:\t1887\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 28, 34, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 26, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 11, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 9, 12, 64)         36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                15370     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 80,949\n",
      "Trainable params: 80,949\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 52s 3ms/step - loss: 2.3231 - val_loss: 2.1748\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 51s 3ms/step - loss: 2.2503 - val_loss: 2.1613\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 46s 3ms/step - loss: 2.2500 - val_loss: 2.1622\n",
      "1.4916362299640091\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "seq_len = 30\n",
    "sample_gap = 30\n",
    "\n",
    "if os.path.exists(path=\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "\n",
    "\"\"\"\n",
    "Train input shape N_samples * seq_len * 108\n",
    "Train label shape N_samples * 1\n",
    "\n",
    "\"\"\"\n",
    "def CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    train_input = train_input.reshape(train_input.shape[0], train_input.shape[1], int(train_input.shape[2] / 3), 3)\n",
    "    test_input = test_input.reshape(test_input.shape[0], test_input.shape[1], int(test_input.shape[2] / 3), 3)\n",
    "    dev_input = dev_input.reshape(dev_input.shape[0], dev_input.shape[1], int(dev_input.shape[2] / 3), 3)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid', input_shape=(train_input.shape[1], train_input.shape[2], train_input.shape[3])))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    CNNIndicatorPred = model.predict(test_input)\n",
    "    CNNacc = np.std(CNNIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return CNNacc\n",
    "CNNacc = CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(CNNacc)\n",
    "# print(pred.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5704781815193638\n"
     ]
    }
   ],
   "source": [
    "def AdaRegress(X, y, n_estimators, random_st):\n",
    "    regr = AdaBoostRegressor(n_estimators=n_estimators, random_state=random_st)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "if os.path.exists(path=\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "\n",
    "pca = PCA(n_components=540)\n",
    "train_input = train_input.reshape(train_input.shape[0], -1)\n",
    "dev_input = dev_input.reshape(dev_input.shape[0], -1)\n",
    "test_input = test_input.reshape(test_input.shape[0], -1)\n",
    "train_input = pca.fit_transform(train_input)\n",
    "dev_input = pca.fit_transform(dev_input)\n",
    "test_input = pca.fit_transform(test_input)\n",
    "\n",
    "regressor = AdaRegress(train_input, np.array(train_label), 100, 0)\n",
    "\n",
    "AdaIndicatorPred = regressor.predict(test_input)\n",
    "AdaBoostacc = np.std(AdaIndicatorPred - np.array(test_label))\n",
    "print(AdaBoostacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_31 (Dense)             (None, 128)               69248     \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 73,649\n",
      "Trainable params: 73,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9012 samples, validate on 1127 samples\n",
      "Epoch 1/3\n",
      "9012/9012 [==============================] - 4s 393us/step - loss: 2.1940 - val_loss: 3.1879\n",
      "Epoch 2/3\n",
      "9012/9012 [==============================] - 1s 114us/step - loss: 2.1442 - val_loss: 4.1296\n",
      "Epoch 3/3\n",
      "9012/9012 [==============================] - 1s 113us/step - loss: 2.1480 - val_loss: 3.6183\n",
      "Epoch 00003: early stopping\n",
      "1.5465264107079268\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(train_input.shape[1], ), kernel_initializer='uniform', activation='sigmoid', kernel_regularizer=keras.regularizers.l1(0.)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "DNNIndicatorPred = model.predict(test_input)\n",
    "DNNacc = np.std(DNNIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "print(DNNacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5416751363111998\n"
     ]
    }
   ],
   "source": [
    "def GBDTRegress(X, y, depth, random_st):\n",
    "    regr = GradientBoostingRegressor(max_depth=depth, random_state=random_st)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "regressor = GBDTRegress(train_input, np.array(train_label), 2, 0)\n",
    "\n",
    "GBDTIndicatorPred = regressor.predict(test_input)\n",
    "GBDTacc = np.std(GBDTIndicatorPred - np.array(test_label))\n",
    "print(GBDTacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5328322535703058\n"
     ]
    }
   ],
   "source": [
    "def RandomForestRegress(X, y, depth, random_st, n_estimators):\n",
    "    regr = RandomForestRegressor(max_depth=depth, random_state=random_st, n_estimators=n_estimators)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "regressor = RandomForestRegress(train_input, np.array(train_label), 2, 0, 100)\n",
    "\n",
    "RFIndicatorPred = regressor.predict(test_input)\n",
    "RFacc = np.std(RFIndicatorPred - np.array(test_label))\n",
    "print(RFacc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:19: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(50, 108), return_sequences=True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_17 (LSTM)               (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_18 (LSTM)               (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9012 samples, validate on 1127 samples\n",
      "Epoch 1/3\n",
      "9012/9012 [==============================] - 35s 4ms/step - loss: 2.1555 - val_loss: 2.7627\n",
      "Epoch 2/3\n",
      "9012/9012 [==============================] - 33s 4ms/step - loss: 2.1317 - val_loss: 2.7666\n",
      "Epoch 3/3\n",
      "9012/9012 [==============================] - 34s 4ms/step - loss: 2.1323 - val_loss: 2.7609\n",
      "Epoch 00003: early stopping\n",
      "1.537528631611567\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path=\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "\n",
    "\"\"\"\n",
    "Train input shape N_samples * seq_len * 108\n",
    "Train label shape N_samples * 1\n",
    "\n",
    "\"\"\"\n",
    "def LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_length=train_input.shape[1], input_dim=train_input.shape[2], return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    LSTMIndicatorPred = model.predict(test_input)\n",
    "    LSTMacc = np.std(LSTMIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return LSTMacc\n",
    "LSTMacc = LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(LSTMacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now try the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length:\t1721577\ttime:\t482.6740942001343\n",
      "(576093,)\n",
      "total data:\t18864\ttotal labels:\t18864\n",
      "train set size:\t15091\tdevelop set size:\t1886\ttest set size:\t1887\n",
      "(15091, 840)\n",
      "1.6108669872490595\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path=\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap, False)\n",
    "    with open(\"./raw_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "        \n",
    "print(train_input.shape)\n",
    "train_input = train_input.reshape(train_input.shape[0], -1)\n",
    "dev_input = dev_input.reshape(dev_input.shape[0], -1)\n",
    "test_input = test_input.reshape(test_input.shape[0], -1)\n",
    "# train_input = pca.fit_transform(train_input)\n",
    "# dev_input = pca.fit_transform(dev_input)\n",
    "# test_input = pca.fit_transform(test_input)\n",
    "\n",
    "def AdaRegress(X, y, n_estimators, random_st):\n",
    "    regr = AdaBoostRegressor(n_estimators=n_estimators, random_state=random_st)\n",
    "    regr.fit(X, y)\n",
    "    return regr\n",
    "\n",
    "regressor = AdaRegress(train_input, np.array(train_label), 100, 0)\n",
    "\n",
    "AdaRawPred = regressor.predict(test_input)\n",
    "AdaBoostacc2 = np.std(AdaRawPred - np.array(test_label))\n",
    "print(AdaBoostacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               107648    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 112,049\n",
      "Trainable params: 112,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 3s 183us/step - loss: 2.2243 - val_loss: 2.3150\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 2s 150us/step - loss: 2.2125 - val_loss: 2.3202\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 3s 177us/step - loss: 2.2090 - val_loss: 2.3094\n",
      "1.5552213955819045\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(train_input.shape[1], ), kernel_initializer='uniform', activation='sigmoid', kernel_regularizer=keras.regularizers.l1(0.)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "DNNRawPred = model.predict(test_input)\n",
    "DNNacc2 = np.std(DNNRawPred - test_label.reshape(test_label.shape[0], 1))\n",
    "print(DNNacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5626932475911746\n"
     ]
    }
   ],
   "source": [
    "regressor = GBDTRegress(train_input, np.array(train_label), 2, 0)\n",
    "\n",
    "GBDTRawPred = regressor.predict(test_input)\n",
    "GBDTacc2 = np.std(GBDTRawPred - np.array(test_label))\n",
    "print(GBDTacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5575153458364646\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegress(train_input, np.array(train_label), 2, 0, 100)\n",
    "\n",
    "RFRawPred = regressor.predict(test_input)\n",
    "RFacc2 = np.std(RFRawPred - np.array(test_label))\n",
    "print(RFacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15091, 30, 28)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:3: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(30, 28), return_sequences=True)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 128)           80384     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 116,705\n",
      "Trainable params: 116,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 46s 3ms/step - loss: 2.2184 - val_loss: 2.3091\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 39s 3ms/step - loss: 2.2138 - val_loss: 2.3098\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 39s 3ms/step - loss: 2.2098 - val_loss: 2.3092\n",
      "1.5552735769548494\n"
     ]
    }
   ],
   "source": [
    "train_input = np.array(train_input).reshape(train_input.shape[0], seq_len, -1)\n",
    "train_label = np.array(train_label)\n",
    "dev_input = np.array(dev_input).reshape(dev_input.shape[0], seq_len, -1)\n",
    "dev_label = np.array(dev_label)\n",
    "test_input = np.array(test_input).reshape(test_input.shape[0], seq_len, -1)\n",
    "test_label = np.array(test_label)\n",
    "\n",
    "print(train_input.shape)\n",
    "\"\"\"\n",
    "Train input shape N_samples * seq_len * 108\n",
    "Train label shape N_samples * 1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "LSTMacc2 = LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(LSTMacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 28, 5, 32)         1184      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 26, 3, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 1, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 416)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                4170      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 14,613\n",
      "Trainable params: 14,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 8s 517us/step - loss: 2.2496 - val_loss: 2.3200\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 7s 437us/step - loss: 2.2140 - val_loss: 2.3138\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 7s 453us/step - loss: 2.2103 - val_loss: 2.3161\n",
      "1.5552674337839474\n"
     ]
    }
   ],
   "source": [
    "def CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    train_input = train_input.reshape(train_input.shape[0], train_input.shape[1], int(train_input.shape[2] / 4), 4)\n",
    "    test_input = test_input.reshape(test_input.shape[0], test_input.shape[1], int(test_input.shape[2] / 4), 4)\n",
    "    dev_input = dev_input.reshape(dev_input.shape[0], dev_input.shape[1], int(dev_input.shape[2] / 4), 4)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid', input_shape=(train_input.shape[1], train_input.shape[2], train_input.shape[3])))\n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='sigmoid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    CNNIndicatorPred = model.predict(test_input)\n",
    "    CNNacc = np.std(CNNIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return CNNacc\n",
    "\n",
    "CNNacc2 = CNNmodel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "print(CNNacc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x15cde1240>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3Xd8leX5x/HPl6ngQAUFR7UurBM1rpaf4qh714VWqQu1zto6qi1qh1oX7gGKqChaN1WcKKLWFRAF3FsQAUFUFEHI9fvjflKOMScJ5CQnJ/m+X6+8cvKscz0nyXM993puRQRmZmbVaVXsAMzMrOlykjAzs7ycJMzMLC8nCTMzy8tJwszM8nKSMDOzvJwkzMwsLycJMzPLy0nCzMzyalPsABZG586dY7XVVit2GGZmJWX06NFfRESXRdm3pJLEaqutRnl5ebHDMDMrKZI+XtR9Xd1kZmZ5OUmYmVleThJmZpaXk4SZmeXlJGFmZnk5SZiZWV5OEmZmlpeThJlZE/btt3DSSTBzZnHev9YkIWmQpKmSxtewTS9JYyVNkPRMtqx7tqzy62tJp2TrzpU0KWfdroU7JTOz5uG772CPPeCaa+D554sTQ11GXA8GrgZurW6lpE7AtcDOEfGJpOUBIuJtoEe2TWtgEnB/zq79I+KSRQ/dzKz5mj0b9toLRo6EW2+F3XYrThy1liQiYhQwo4ZNDgbui4hPsu2nVrPN9sD7EbHIQ8PNzFqK77+HffeFESPg5pvht78tXiyFaJNYG1hG0khJoyUdVs02BwFDqyw7QdLrWXXWMgWIw8ys5M2ZA/vtB48+CgMHQp8+xY2nEEmiDbApsBuwE/BXSWtXrpTUDtgTuDtnn+uANUjVUZOBS/MdXFJfSeWSyqdNm1aAcM3Mmqa5c+GAA+Dhh+GGG+DII4sdUWGSxETgsYj4NiK+AEYBG+Ws3wUYExFTKhdExJSImB8RFcBAYPN8B4+IARFRFhFlXbos0pNuzcyavB9+gIMOgmHDUkN1377FjigpRJJ4EOgpqY2kDsAWwJs563tTpapJUrecH/cB8vacMjNr7ubNg0MOgfvvhyuugN//vtgRLVBr7yZJQ4FeQGdJE4FzgLYAEXF9RLwp6VHgdaACuDEixmf7dgR+DRxT5bAXSeoBBPBRNevNzFqEefPg0EPh7rvhssvSmIimRBFR7BjqrKysLDzpkJk1F/Pnw+9+B0OGwL/+Baef3jDvI2l0RJQtyr4ecW1mVgQVFalhesgQ+Oc/Gy5B1JeThJlZI6uoSA3Tt9wC550HZ51V7Ijyc5IwM2tEFRVw3HFw003w179Cv37FjqhmThJmZo0kAk48EQYMgD//OZUimjonCTOzRhABp5wC114Lp52W2iGkYkdVOycJM7MGFgF//CNceSX84Q+pJ1MpJAhwkjAza1ARcOaZ0L9/qmq69NLSSRDgJGFm1mAi4C9/gYsuSo3VV1xRWgkCnCTMzBrMeefB+efD0UfD1VeXXoIAJwkzswbx97+nJHH44XD99dCqRK+2JRq2mVnTdcEFafzDYYelOSFKNUGAk4SZWUFdfHEaQX3wwTBoELRuXeyI6sdJwsysQPr3T89gOvDA9MiNUk8Q4CRhZlYQV10Fp56aph4dMgTa1DoRQ2lwkjAzq6drr03zQOyzD9xxR/NJEOAkYWZWLwMGwPHHwx57wJ13Qtu2xY6osJwkzMwW0aBBcMwxsOuuaWa5du2KHVHhOUmYmS2CW2+Fo46CHXeEe++F9u2LHVHDqDVJSBokaaqk8TVs00vSWEkTJD2Ts/wjSeOydeU5y5eV9ISkd7Pvy9T/VMzMGsftt6dpR7fbDh54ABZbrNgRNZy6lCQGAzvnWympE3AtsGdErAfsX2WTbSOiR5X5Vc8ERkTEWsCI7GczsybvrrvSILlttoFhw2DxxYsdUcOqNUlExChgRg2bHAzcFxGfZNtPrcP77gXckr2+Bdi7DvuYmRXVPffAIYfAr34FDz0EHToUO6KGV4g2ibWBZSSNlDRa0mE56wJ4PFveN2f5ChExOXv9ObBCvoNL6iupXFL5tGnTChCumdnCu/9+6N0bttwSHn4YOnYsdkSNoxC9edsAmwLbA4sDL0h6MSLeAXpGxCRJywNPSHorK5n8T0SEpMh38IgYAAwAKCsry7udmVlDGTYMDjgAyspg+HBYcsliR9R4ClGSmAg8FhHfRsQXwChgI4CImJR9nwrcD2ye7TNFUjeA7HtdqqjMzBrdww+nUdQbbwyPPgpLLVXsiBpXIUoSDwJXS2oDtAO2APpL6gi0iohvstc7An/L9hkG9AEuzL4/WIA48jr77DTIZcUVYaWV0lfV1yuu2PwboMxs4Tz2GOy7L2ywATz+OCy9dLEjany1JglJQ4FeQGdJE4FzgLYAEXF9RLwp6VHgdaACuDEixktaHbhfaZaNNsAdEfFodtgLgX9LOhL4GDigsKf1Y+uuC1tsAZ99BqNHp6Lj7Nk/3W6ZZfInkcrvyy/fPB7aZWY1e/JJ2HvvdP144gno1KnYERWHIkqnmr+srCzKy8tr37AWEfDVVzBpUkockyZV//rzz6Gi4sf7tm4N3br9OHFUl1iWXLI0Z6EyM3j6adhtN1hzTXjqKejcudgR1Y+k0VWGIdRZM3oMVd1J6a6gUydYb738282bB1On5k8ib7+d/phmzvzpvh071pxEVlwxJZvmOIzfrJSNGgW77w6rrw4jRpR+gqivFpkk6qpNmwXtFZttln+7b79NSSNfqeT559PPc+f+dN8uXaqv1spd1rmzSyU1iUgJfe7c9LpNm1Tia9PGn5stnOefT89h+tnPUoLo0qXYERWfk0QBdOwIa62VvvKJgC++WJA8qksoL78M1Q0FadduQbKqqXTSEAN7ImD+/HQBnjMnfa/8Wpif67NvbceqTA7VkX6cNJrb9zZtYP31W1aXzIbywguw887pf+mpp2CFvKO3WhYniUYipbuSLl1go43ybzd3LkyenL9U8tprqZ/2t9/+dN+ll/5x4lhyycJcjBui2apduwVf7dtX/7pdO1hiifzrqv7crl36nOfPTyWLQn+fO7f65QtzjIb4LDt0SD1w+vSBbbd1x4pF8fLLKUF07ZoSRLduxY6o6XCSaGLatYNVV01f+UTAN9/kbyuZNAnefDMlkvbt81+EF188tcvU9YJd13W1bdu2bcutBqqoSAmjUIlr9uz0eIi77kqzoa28Mhx6aEoY3bsX+2xLw+jR6UmunTunNsaVVip2RE1Li+zdZNbczJ6dunbfckvq219Rkbp99+mT5ltedtliR9g0vfoqbL99GiD3zDM135yVsvr0bvJ8EmbNwOKLp2QwfDhMnAgXX5xKkr//fao62X//VOL44YdiR9p0vP467LBDqtJ8+unmmyDqy0nCrJnp1g3+9Kd0ERw9Go49FkaOTNNrrrwynHpqattqycaPTyWIxRdPCeLnPy92RE2Xk4RZMyXBJpvAFVekdqoHH4SePeHqq6FHj/TVvz9MmVLsSBvXm2+mBNG2bUoQa6xR7IiaNicJsxagXTvYc880zebkySlRtGuXShUrrZRKGffck3q0NWdvv51mk5NSgqip27olThJmLcxyy8Hxx6dunxMmpKqpMWNSu0W3bnDccfDiiw3TXbeY3n03dRGuqEjdXN37q26cJMxasHXXhQsvhE8+Sb2idtkl9ZDaaiv4xS/g/PPh00+LHWX9vf9+ShA//JBGUq+7brEjKh1OEmZG69ZprMDtt6cHW954Y3ri8dlnp14/O+wAt91W/SDOpu7DD1OCmD07JYj11y92RKXFScLMfmSppeDII9OD7t5/H/r1gw8+gMMOSyOSDz889Zaq+oTkpujjj1MbxKxZ6dHfG25Y7IhKj5OEmeW1+upw7rnw3ntpsNkBB6TG7223Tb2C+vVL65qiTz9NCeLLL9N8EBtvXOyISpOThJnVqlUr2HpruOmmVB01ZAisvTb84x+ph1DPnjBwYJqnpSmYNCkliC++SDPKbbppsSMqXU4SZrZQOnSAQw5JDd2ffpoavmfMgL59U3VU795pLuh584oT3+TJKUF8/nmKY/PNixNHc1FrkpA0SNJUSeNr2KaXpLGSJkh6Jlu2iqSnJb2RLT85Z/tzJU3K9hkradfCnI6ZNaaVVoIzzkhdaV9+ObVlPP546iX1s5/Baael0c2NZcqUNFBu0iR45JHUS8vqp9YH/EnaGpgF3BoRP+kXIKkT8F9g54j4RNLyETFVUjegW0SMkbQkMBrYOyLekHQuMCsiLlmYYP2AP7Omb84cePjh1JV2+PBUothkk/SwwYMPbriZ3qZNS20lH36YEsTWWzfM+5SiBn3AX0SMAmbUsMnBwH0R8Um2/dTs++SIGJO9/gZ4E/BDeM2aufbt0/wWDz6Y7ugvvzwNzDv55DRYb++94f77q5+pcVF98UUqQXzwQXqQoRNE4RSiTWJtYBlJIyWNlnRY1Q0krQZsDLyUs/gESa9n1VnLFCAOM2till8+JYcxY9IDB08+OY3m3nffNDnWiSdCeXn9RnfPmAG//nUaUT1sWCpNWOEUIkm0ATYFdgN2Av4qae3KlZKWAO4FTomIr7PF1wFrAD2AycCl+Q4uqa+kcknl06qb29PMSsIGG8All6RHmT/8cBqgN3Bgmj9+/fXhoovSpFkL48svU4J44w144IF0TCusQiSJicBjEfFtRHwBjAI2ApDUlpQgbo+I+yp3iIgpETE/IiqAgUDe/gcRMSAiyiKirItnJTcreW3awK67wp13ph5IN9yQZkg84wxYZZU0jejQoWmEdE2++gp22gnGjUvVVzvt1DjxtzSFSBIPAj0ltZHUAdgCeFOSgJuANyPistwdskbtSvsAjdj/wcyaik6dUtfZ55+Hd96Bs85Kj/I++ODUnfboo+G5535aHfX11ymZvPpqenrtru4f2WDq0rtpKNAL6AxMAc4B2gJExPXZNqcBhwMVwI0RcbmknsCzwLhsOcBZETFc0m2kqqYAPgKOiYjJtQXr3k1mzV9FRRrdfcstKQF8+20a3X3YYemrc+eUIF58Ee6+G/bZp9gRN3316d3kOa7NrMmaNQvuuy8ljKefTiWKrl1Td9ehQ9Pjza12nuPazJqlJZZIpYcRI+Cjj9JjQH72M7jjDieIxuKShJlZM+eShJmZNQgnCTMzy8tJwszM8nKSMDOzvJwkzMwsLycJMzPLy0nCzMzycpIwM7O8nCTMzCwvJwkzM8vLScLMzPJykjAzs7ycJMzMLC8nCTMzy8tJwszM8nKSMDOzvOqUJCQNkjRV0vgatuklaaykCZKeyVm+s6S3Jb0n6cyc5T+X9FK2/C5J7ep3KmZmVmh1LUkMBnbOt1JSJ+BaYM+IWA/YP1veGrgG2AVYF+gtad1st38B/SNiTeBL4MhFOQEzM2s4dUoSETEKmFHDJgcD90XEJ9n2U7PlmwPvRcQHETEXuBPYS5KA7YB7su1uAfZehPjNzKwBFapNYm1gGUkjJY2WdFi2fCXg05ztJmbLlgNmRsS8Kst/QlJfSeWSyqdNm1agcM3MrC7aFPA4mwLbA4sDL0h6sRAHjogBwACAsrKyKMQxzcysbgqVJCYC0yPiW+BbSaOAjbLlq+RstzIwCZgOdJLUJitNVC43M7MmpFDVTQ8CPSW1kdQB2AJ4E3gFWCvrydQOOAgYFhEBPA3sl+3fJzuGmZk1IXUqSUgaCvQCOkuaCJwDtAWIiOsj4k1JjwKvAxXAjRExPtv3BOAxoDUwKCImZIc9A7hT0j+AV4GbCnZWZmZWEEo39aWhrKwsysvLix2GmVlJkTQ6IsoWZV+PuDYzs7ycJMzMLC8nCTMzy8tJwszM8nKSMDOzvJwkzMwsLycJMzPLy0nCzMzycpIwM7O8nCTMzCwvJwkzM8vLScLMzPJykjAzs7ycJMzMLC8nCTMzy8tJwszM8nKSMDOzvGpNEpIGSZoqaXye9b0kfSVpbPbVL1vePWfZWElfSzolW3eupEk563Yt7GmZmVkh1GWO68HA1cCtNWzzbETsnrsgIt4GegBIag1MAu7P2aR/RFyyUNGamVmjqrUkERGjgBn1fJ/tgfcj4uN6HsfMzBpRodoktpL0mqRHJK1XzfqDgKFVlp0g6fWsOmuZAsVhZmYFVIgkMQZYNSI2Aq4CHshdKakdsCdwd87i64A1SNVRk4FL8x1cUl9J5ZLKp02bVoBwzcysruqdJCLi64iYlb0eDrSV1Dlnk12AMRExJWefKRExPyIqgIHA5jUcf0BElEVEWZcuXeobrpmZLYR6JwlJXSUpe715dszpOZv0pkpVk6RuOT/uA1Tbc8rMzIqr1t5NkoYCvYDOkiYC5wBtASLiemA/4DhJ84DZwEEREdm+HYFfA8dUOexFknoAAXxUzXozMwOYPx/uuAN694Y2demQWli1vmNE9K5l/dWkLrLVrfsWWK6a5YfWNUAzsxbrrbfgiCPghRegXTs48MBGD8Ejrs3Mmpp58+CCC6BHj5Qobr0VDjigKKE0ftnFzMzye+21VHoYMwZ+8xu4+mro2rVo4bgkYWbWFMyZA/36QVkZTJwId98N99xT1AQBLkmYmRXfyy+n0sOECfDb38Lll8NyP2nOLQqXJMzMimX2bDjtNNhqK5g5Ex56CG67rckkCHBJwsysOJ59Fo48Et59F44+Gi6+GJZeuthR/YRLEmZmjembb+CEE2DrrVMvpiefhAEDmmSCACcJM7PG88QTsMEGcO21cPLJMG4cbL99saOqkZOEmVlDmzkzVS3tuCMstliqarr8cujYsdiR1cpJwsysIQ0bBuuuC7fcAmeeCWPHwq9+Veyo6sxJwsysIUybBgcfDHvtBV26wEsvpVHUiy1W7MgWipOEmVkhRcBdd6XSwz33wHnnwSuvwKabFjuyReIusGZmhTJ5Mhx3HDz4IGy2GQwaBOuvX+yo6sUlCTOz+oqAwYNT6eGxx+Cii+C//y35BAEuSZiZ1c/HH8Mxx6Tk0LMn3HQTrL12saMqGJckzMwWRUUFXHddKi089xxcdRU880yzShDgkoSZ2cJ777007mHUKNhhBxg4EFZbrdhRNYhaSxKSBkmaKqnaeagl9ZL0laSx2Ve/nHUfSRqXLS/PWb6spCckvZt9X6Ywp2Nm1oDmz4dLL4UNN0zzPtx4Izz+eLNNEFC36qbBwM61bPNsRPTIvv5WZd222fKynGVnAiMiYi1gRPazmVnTNWFCGgT3pz+l0sOECak0IRU7sgZVa5KIiFHAjAK/717ALdnrW4C9C3x8M7PC+OEH+Mc/YJNNUjXTHXekLq4rrVTsyBpFoRqut5L0mqRHJK2XszyAxyWNltQ3Z/kKETE5e/05sEKB4jAzK5xXX4XNN4e//hX23hveeAN69272pYdchUgSY4BVI2Ij4CrggZx1PSNiE2AX4HhJW1fdOSKClEyqJamvpHJJ5dOmTStAuGZmtfj+ezj77DQg7vPP4b770ijq5ZcvdmSNrt5JIiK+johZ2evhQFtJnbOfJ2XfpwL3A5tnu02R1A0g+z61huMPiIiyiCjr0qVLfcM1M6vZiy+mqqXzz4dDD02lh332KXZURVPvJCGpq5TKXpI2z445XVJHSUtmyzsCOwKVPaSGAX2y132AB+sbR40qKtKjes3M8vnuOzj1VPjlL2HWLHjkEbj5ZlimZXe+rHWchKShQC+gs6SJwDlAW4CIuB7YDzhO0jxgNnBQRISkFYD7s/zRBrgjIh7NDnsh8G9JRwIfAwcU9KyqOu00GD48zQDVQhqbzGwhPP00HHUUfPBBevbShRfCUksVO6omQalJoDSUlZVFeXl57RtWNWoU7LZbqk8cMaJZ92k2s4Xw9ddwxhlw/fWwxhpp3EOvXsWOquAkja4yDKHOWsZjObbeOiWHGTPg//4P3nmn2BGZWbE98kh6pMYNN6Rqptdfb5YJor5aRpKA1I1t5EiYMycljXHjih2RmRXDjBnwu9/BrrvCEkukp7Veeil06FDsyJqklpMkADbaKFU9tW6d7hgWperKzErX/fenx3kPGZK6uL76Kmy5ZbGjatJa3gP+1lknTUK+/faw3XapQbtnz2JHZbbA/PmpN96MGTB9es3fv/wSOneG7t3T33b37umra9cWNeCrVlOnwgknwN13Q48eqapp442LHVVJaHlJAmD11VOi2GEH2HHHNMT+178udlTW3FRUpIbR2i70ld8rX8+cmSaxqY4EnTrBcsvBssum7pmTJ6dHVH/33YLtllpqQcKoTB7rrANrrllycyzXSwQMHQonnQTffJMer3H66dC2bbEjKxktM0kArLxy+sfacUfYffc0F+0eexQ7KmuKItIFZmEu9JWvKyryH3fppdOFvvKCv8Ya6XvusqrfO3VK1aVVVVTAxInw9tvw1lvp+9tvp3a4IUMWbCel3n25pY7K182t9DFpEhx7LDz0EGyxRZpKdN11ix1VyWkZXWBrMmMG7LxzqpscMgQOPLCwx7emIyLdbS/snf2MGTBvXv7jLrFE/ot6vgv+MstAm0a6R/v229SjrzJ5VH5/553aSx/du8Naa5VW6SMizQ73xz8ueDjfySdXn1xbiPp0gXWSgFQlsPvu8PzzqZ/04YcX/j2s4Y0alXqq5LvQT58Oc+fm379Dh5rv4vMta9eu8c6xkHJLH1VLIJ9+umC7ytJH1aqrplj6+PBD6Ns3DZzdZpv0/7zmmsWOqujqkyRabnVTrqWWgkcfTc9nOeKIdHd1/PHFjsrqqqICzj0X/v739HP79j++mK+9dt0u+KV0t1wIrVrBz36Wvqq2yVUtfVQmkVGj8pc+cpNHY5c+Kirgmmvgz39OSeu661KyaNWyOnA2BCeJSh06wLBhqbrphBPSP8nppxc7KqvNzJnw29/Cww+nvu9XXAFLLtm07m5LUceOqfdP1R5AFRWprr9q8njmmerbPqprPC906eOdd9LkP889BzvtBAMGpMRnBeEkkat9+9RFrk+fNFR/1iw47zxfcJqqN95Iz/j/8MN0F3nccf5dNbRWrWCVVdJXvtJH1aqrqqWPJZf8abvHOussfOlj3jy47DLo1w8WXxwGD4bDDvPfQIE5SVTVti3cdlsqWfz97ylRXHqp//CamvvuS8m8Qwd46qn0uBUrrtpKH7nJI1/pY9VVf9ru0b07dOv24//BceNS1XB5ebpRuPbatI0VnJNEdVq3TkXWjh2hf/90h3Tdda7fbArmz4dzzoF//jM9auXee1N3Zmu6cksfO+zw43W5pY/cJJKv9NG9e+pNNmhQ6g58112w//6+iWtAThL5tGoFl1+eEsUFF6Q/2Jtvbrxui/ZTM2fCwQen0bJHHJGqmFpaY3NzszClj8rkMWlSaju88so02twalK94NZHS7FRLLJGe8/Ldd2n0Zql2eSxl48en3mcff5xKdccc47vH5qym0sf8+S16zENjc/1JXZx1Vqp2uu++VP85e3axI2pZ7rknPYRt1qw0OcyxxzpBtGROEI3KSaKuTjkltVM8+mh6xPA33xQ7ouZv/vzU733//WGDDWD0aPjVr4odlVmL4iSxMI4+OvXGePbZ9MynL78sdkTN14wZaTbBCy9Mn/vIkbDiisWOyqzFqTVJSBokaaqk8XnW95L0laSx2Ve/bPkqkp6W9IakCZJOztnnXEmTcvbZtXCn1MAOPjhVf4wZkx41Pm1asSNqfsaNg802S11bb7ghleDaty92VGYtUl1KEoOBnWvZ5tmI6JF9/S1bNg/4Y0SsC2wJHC8p9xGM/XP2Gb7QkRfT3nun0dlvvZWeD/PZZ8WOqPn4979T+8Ps2akffd++xY7IrEWrNUlExChgxsIeOCImR8SY7PU3wJvASgsdYVO1006pfeLTT9NAro8+KnZEpW3+/DTK/cAD06Qwo0fDVlsVOyqzFq9QbRJbSXpN0iOS1qu6UtJqwMbASzmLT5D0eladtUyB4mhc22yTnjY5Y0aaN/udd4odUWmaMSN1BrjootRz6emnPXrWrIkoRJIYA6waERsBVwEP5K6UtARwL3BKRHydLb4OWAPoAUwGLs13cEl9JZVLKp/WFOv/t9giNap+/31KFOOrbbqxfF57DcrK0mc4cGAaA+FxKGZNRr2TRER8HRGzstfDgbaSOgNIaktKELdHxH05+0yJiPkRUQEMBDav4fgDIqIsIsq6dOlS33AbxkYbpZGgrVun0kVDzHnRHN15Z6pSmjMnfX5HHVXsiMysinonCUldpTSySdLm2TGnZ8tuAt6MiMuq7JNbl7APUPq33+usk7rGLrVU6vX03HPFjqjpmjcPTjsNeveGTTZJ7Q9bbFHsqMysGnXpAjsUeAHoLmmipCMlHSvp2GyT/YDxkl4DrgQOijTd3a+AQ4HtqunqepGkcZJeB7YF/lDoEyuK1VdPiaJbt9Sw/eSTxY6o6Zk+HXbZBS65BH7/+9TNtWvXYkdlZnl4+tKGMGVKetb+O++k+Sn22KPYETUNY8em5y999llqezjiiGJHZNYi1Gf6Uo+4bggrrJAaYjfcEPbdN/X9b+nuuAN++cs0Mf2zzzpBmJUIJ4mGsuyyqbppyy1T3fvgwcWOqDjmzYNTT4VDDkm9mEaPTvNAmFlJcJJoSEstlQbcbb89HH54mj2rJZk2LbXN9O8PJ54II0akUpaZlQzPJ9HQOnaE//wnjSQ+/vj0uOvTTy92VA1vzJjU/jBlSipF9elT7IjMbBG4JNEY2rdPDdgHHZQePdGvH5RQh4GFNmRIeqR3RUXqCuwEYVayXJJoLG3bpotnhw7w97+nuX0vuaR5TZ7zww+plHT55WlQ4b//DcsvX+yozKwenCQaU+vW6dETHTvCZZelRHHttWmqxlI3dWqqUhs5Ek4+GS6+OCVGMytpThKNrVUruOKKlCguvDDNmz1oELQp4V9FeXnq6jttGtx6Kxx6aLEjMrMCKeErUwmT4IILYMkl4eyzU6K4447SfLDdrbemOR9WWAGefz49ZsPMmo1mUM9Rws46K3UPvffeNJHR7NnFjqjufvgBTjopNUr/8pepNOEEYdbsOEkU2ymnpOk5H300zanwzTfFjqjYtu+FAAANaklEQVR2U6bADjvAVVfBH/4Ajz8OTfUJvWZWL65uagqOPjr1eurTB3bcER55BDp1KnZU1XvlldT+MH166q11yCHFjsjMGpBLEk3FIYeksRSjR8O226ZG4KZm8OA0VWvr1qn9wQnCrNlzkmhK9tkHhg2Dt96CXr3S01Kbgrlz4YQT0qNFevZM7Q8bb1zsqMysEThJNDU775zaJz75JE2H+vHHxY3n88/Ts6euuQb+9KcUW+fOxY3JzBqNk0RTtM026Qmy06en6p133y1OHC+9tODJrUOHpgFypTyew8wWmpNEU7XFFmn08vffp0QxvpFneL3pplSSadsWXnghPXfKzFqcOiUJSYMkTZVU7ZVKUi9JX+VMU9ovZ93Okt6W9J6kM3OW/1zSS9nyuySV4EiyBrbRRvDMM6mheJtt0h19Q5s7F447Do46Kr1neXmKw8xapLqWJAYDO9eyzbMR0SP7+huApNbANcAuwLpAb0nrZtv/C+gfEWsCXwJHLmzwLcIvfpFmcltqKdhuu9SrqKFMnpx6Vl1/fXpQ3/DhsNxyDfd+Ztbk1SlJRMQoYMYiHH9z4L2I+CAi5gJ3AntJErAdcE+23S3A3otw/JZh9dVh1Cjo2jWNoxgxovDv8eKLqf1h7Fi4807417/c/mBmBW2T2ErSa5IekbRetmwl4NOcbSZmy5YDZkbEvCrLLZ9VVkmJYvXVYbfd4KGHCnfsgQNT+8Nii6X2hwMPLNyxzaykFSpJjAFWjYiNgKuABwp0XCT1lVQuqXxaUxxg1phWWCE1Zm+wQRpTcffd9TvenDlwzDHpAX3bbZdGU2+4YUFCNbPmoSBJIiK+johZ2evhQFtJnYFJwCo5m66cLZsOdJLUpsry6o49ICLKIqKsi58PlNoIRoyALbdMPY4GD16043z2WWp/GDAA/vxnePhhWHbZgoZqZqWvIElCUtesnQFJm2fHnQ68AqyV9WRqBxwEDIuIAJ4G9ssO0Qd4sBCxtAhLLZUGtW2/fRoFfe21C7f/f/8Lm24Kr7+eSiPnn596UJmZVVHXLrBDgReA7pImSjpS0rGSjs022Q8YL+k14ErgoEjmAScAjwFvAv+OiAnZPmcAp0p6j9RGcVPhTqsF6NgxPcJjzz3h+OPTQLfaRMANN6RHfnTsmBqr99uv1t3MrOVSuqkvDWVlZVFeXl7sMJqWH35IM8HddRf06wfnnlv9vNlz5qTnL914I+yyC9x+OyyzTKOHa2aNT9LoiChblH3dx7HUtW2bLvgdOsDf/pbmzb744h8nikmT4De/SY/ZOPtsOO88Vy+ZWZ04STQHrVunEsISS8Cll6ZEcc01aT7t555LVUqzZqUZ8Pbdt9jRmlkJcZJoLlq1giuuSG0NF16YEsUWW6SZ737+89Qjar31aj+OmVkOJ4nmRIILLkglir/8BW67LQ28GzKk6c50Z2ZNmpNEc3T22bDiijBjRpqDupUf9mtmi8ZJork6/PBiR2BmzYBvMc3MLC8nCTMzy8tJwszM8nKSMDOzvJwkzMwsLycJMzPLy0nCzMzycpIwM7O8SupR4ZKmAR8v4u6dgS8KGE4p8Dm3DD7nlqE+57xqRCzS1J4llSTqQ1L5oj5PvVT5nFsGn3PLUKxzdnWTmZnl5SRhZmZ5taQkMaDYARSBz7ll8Dm3DEU55xbTJmFmZguvJZUkzMxsIZV8kpA0X9JYSRMkvSbpj5JaZet6SQpJe+Rs/5CkXtnrkZLKc9aVSRrZ2OewKCR1lXSnpPcljZY0XNLa2fmemLPd1ZJ+l70eLGmSpPbZz50lfVScM6gbSbOqWdY9+92NlfSmpAGSdsp+HitplqS3s9e35vwdHJVzjB7Zsj817hnVTNIKku6Q9EH2e31B0j7ZOXyVndPrkp6UtHy2z+8kTZP0qqR3JT0m6ZfZumuyfd6QNDvnM9pvIeOq/D8bL+k/kgoy1aGk1SSNL9CxBkv6MOccTyrEcfO8V6/Kz7iadXtnf1vr1BBnjZ9/lXN5S9I5hYi7Sozr1mXbkk8SwOyI6BER6wG/BnYBcj/QicDZNey/vKRdGjLAQpMk4H5gZESsERGbAn8GVgCmAidLapdn9/nAEY0TaYO5Euif/d5/AVwVEY9lP/cAyoFDsp8Py/YZDxyQc4zewGuNG3bNst/rA8CoiFg9+70eBKycbfJsdk4bAq8Ax+fsfldEbBwRawEXAvdJ+kVEHJ99JrsC71d+RhFxz0KGV/l/tj4wo8p7NyWn5ZzjlXXdSVLrhXyfXkC1SYL0t/Vc9r0+Tst+dz2APpJ+Xs/j5dobaDFJ4n8iYirQFzgh+4eDdCH4StKv8+x2MTUnkaZoW+CHiLi+ckFEvAZ8CkwDRgB98ux7OfAHSaU8K2E3UvIHICLG1WGfj4HFsjt1ATsDjzRQfItqO2Buld/rxxFxVe5GWfxLAl9Wd5CIeJrUyNm3geJ8AVgpi2UJSSMkjZE0TtJe2fLVslLewKyU/7ikxbN1m2al/tfISTaSFpN0c3acVyVtmy3/naQHJD0h6SNJJ0g6NdvmRUnL1hSspN7ZMcdL+lfO8lmSLs3i2CqL65msBPeYpG7ZdidlJbHXlUrvqwHHkv6Pxkr6v5xjLgH0BI4kJXiUXK1Uun0SWD5n+36SXsliG5Bz3cq1WPb922yf7bNzHydpkBbUDORbfmFO/JdkJaA9gYuz+Neo6fNrVkkCICI+AFqT84sA/gn8Jc8uLwBzK/8gS8T6wOga1v8L+FOeu6NPSHc5hzZEYI2kP/CUpEck/WEhqj7uAfYn3QGOAeY0VICLaD1SXPn8n6SxpN/hDsCgGrYdA1Rb3VEf2d/U9sCwbNH3wD4RsQnp5uXSnAvdWsA1WSl/JvCbbPnNwIkRsVGVwx8PRERsQLoLv0VS5QVyfWBfYDPS//N3EbEx6f/3sJxjVF74xkraQNKKpP+H7Uh35JtJ2jvbtiPwUhbHS8BVwH5ZCW5Q9j4AZwIbZyW4YyPiI+B6FpRmn815/72ARyPiHWC6pE2BfYDupDv3w/hxCeTqiNgsK6EtDuxe9VxIN0R3RsTU7PMYDByYfU5tgONqWL5c9v7rZfH/IyL+S/r9VZa63qcGzS5JVCciRgFI6plnk3+QP4mUnCxRvgQcnGeTC4DTKNHff0TcDPwCuJtU7H+x8q6pFv8mJYnewNAGC7BAlNoTXpP0SraosrppFdKF9qKadi9wOItnF6zPSdWaT+S8z/mSXgeeJJUwVsjWfRgRY7PXo4HVsoTeqfJ/Ergt5z16AkMAIuItUulv7Wzd0xHxTURMA74C/pMtHweslnOM3OqmcaSkMjIipkXEPOB2YOts2/nAvdnr7qRE9ER2nn9hQTXf68Dtkn4LzKvlc+oN3Jm9vjP7eWtgaETMj4jPgKdytt9W0kuSxpES2XpVzwXoCmyflQC6kz7Xd7JtbsmOn2/5V6REfpOkfYHvaon/J0ryIlETSauTfvlTq6zKW5qIiKdIWXzLho2uYCYAm9ayzfnAGVRzsYiId4Gx/LiOvqRExGcRMSgi9iL9465fh30+B34gtV2NaOAQF8UEYJPKHyLieNJde3XP3BnGgotddTYG3ixgbLOzC9aqpL+pymqiQ7L4Ns3WT2FB9UhuSW0+6e52UeUeqyLn54p6HPf7iJifvRYwISfBbBARO2brdgOuIf1uXslXVZtVe20H3KjUIeQ00v9YtQk7u/u/llR62QAYyILP7n8iYhYwkpREF0qWGDcnlaJ3Bx5d2GM0qyQhqQupGHh1VBkAEhGPA8sAG+bZ/R/A6Q0bYcE8BbSX9L86Z0kbAqtU/pzdib0B7PHT3YGUNJtUz566krSzpLbZ667AcsCkOu7eDzgj5+LQlDxFajc5LmdZhzzb9gSqrSaQtA2pPWJgYcODiPgOOAn4Y3axXBqYGhE/ZFW2q9ay/0xgZk6p/pCc1c9W/ixpbeBnwNv1DPllYBulnnytSXf2z1Sz3dtAF0lbZe/fVtJ6Sj0lV8naec4gne8SwDekdqFc+wG3RcSqEbFaVuL7EJgOHCipddbOUVm1XZkQvsjaMqrt8ZR9zluQft9vk0pka2arD83Op9rl2XGXjojhwB+Ayiq+6uKvVik3XlaqLAa3Jd1R3gZclmfbfwIPVrciIoYrPWW2yYuIkLQPcLmkM0jFyY+AU6ps+k/g1TzHmCBpDDl3rk1UB0kTc36+jFQNcIWk77Nlp2WlhFpl9bFNUvZ73RvoL+l0UieEb0kXJ1jQJiFSNcJRObsfmF14O5AuTL+JiEKWJHLjfDWrXupNqr75T1ZdUg68VYdDHA4MkhTA4znLrwWuy441D/hdRMypvi23zrFOlnQm8DTpc3s4In5yDYiIuUrdUq+UtDTp2ng58A4wJFsm4MqImCnpP8A9Sg31J2btEr1J7R+57iVVjb5Lumn7hNSOQnacgaSed5+TeqzluljSX4B2pJLvfdnfyOHA3VnyeAW4PvucfrIcWBZ4MCu1CDg1O/adwEClbsL71dQu4RHXZmaWV7OqbjIzs8JykjAzs7ycJMzMLC8nCTMzy8tJwszM8nKSMDOzvJwkzMwsLycJMzPL6/8BNGBvD5n9HS0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(['DNN', 'CNN', 'LSTM', 'GBDT', 'RandomForest', 'AdaBoost'], [DNNacc, CNNacc, LSTMacc, GBDTacc, RFacc, AdaBoostacc], 'red', label='indicator')\n",
    "plt.plot(['DNN', 'CNN', 'LSTM', 'GBDT', 'RandomForest', 'AdaBoost'], [DNNacc2, CNNacc2, LSTMacc2, GBDTacc2, RFacc2, AdaBoostacc2], 'blue', label='raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Different N & Sample Gaps\n",
    "Using LSTM model as an example, we can show the different accuracy or say, MSE loss by choosing distinct value of n & sample gaps & sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(50, 108), return_sequences=True)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 9012 samples, validate on 1127 samples\n",
      "Epoch 1/3\n",
      "9012/9012 [==============================] - 32s 4ms/step - loss: 2.1649 - val_loss: 2.7724\n",
      "Epoch 2/3\n",
      "9012/9012 [==============================] - 29s 3ms/step - loss: 2.1365 - val_loss: 2.7695\n",
      "Epoch 3/3\n",
      "9012/9012 [==============================] - 33s 4ms/step - loss: 2.1282 - val_loss: 2.7560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quan/Library/Python/3.5/lib/python/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(100, 108), return_sequences=True)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 100, 128)          121344    \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4452 samples, validate on 556 samples\n",
      "Epoch 1/3\n",
      "4452/4452 [==============================] - 33s 7ms/step - loss: 2.1655 - val_loss: 2.4160\n",
      "Epoch 2/3\n",
      "4452/4452 [==============================] - 33s 7ms/step - loss: 2.1391 - val_loss: 2.3849\n",
      "Epoch 3/3\n",
      "4452/4452 [==============================] - 33s 7ms/step - loss: 2.1189 - val_loss: 2.4428\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8957 samples, validate on 1120 samples\n",
      "Epoch 1/3\n",
      "8957/8957 [==============================] - 32s 4ms/step - loss: 11.2796 - val_loss: 10.3049\n",
      "Epoch 2/3\n",
      "8957/8957 [==============================] - 30s 3ms/step - loss: 11.2122 - val_loss: 10.2877\n",
      "Epoch 3/3\n",
      "8957/8957 [==============================] - 32s 4ms/step - loss: 11.2082 - val_loss: 10.2989\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_7 (LSTM)                (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4424 samples, validate on 553 samples\n",
      "Epoch 1/3\n",
      "4424/4424 [==============================] - 17s 4ms/step - loss: 11.6457 - val_loss: 10.1186\n",
      "Epoch 2/3\n",
      "4424/4424 [==============================] - 14s 3ms/step - loss: 11.5284 - val_loss: 9.9799\n",
      "Epoch 3/3\n",
      "4424/4424 [==============================] - 14s 3ms/step - loss: 11.5431 - val_loss: 9.9474\n",
      "Epoch 00003: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_9 (LSTM)                (None, 50, 128)           121344    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4391 samples, validate on 549 samples\n",
      "Epoch 1/3\n",
      "4391/4391 [==============================] - 17s 4ms/step - loss: 22.9083 - val_loss: 25.1255\n",
      "Epoch 2/3\n",
      "4391/4391 [==============================] - 15s 3ms/step - loss: 22.7617 - val_loss: 25.0318\n",
      "Epoch 3/3\n",
      "4391/4391 [==============================] - 15s 3ms/step - loss: 22.7281 - val_loss: 25.2659\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 100, 128)          121344    \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 50)                35800     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 157,665\n",
      "Trainable params: 157,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4391 samples, validate on 549 samples\n",
      "Epoch 1/3\n",
      "4391/4391 [==============================] - 36s 8ms/step - loss: 23.4998 - val_loss: 19.9841\n",
      "Epoch 2/3\n",
      "4391/4391 [==============================] - 31s 7ms/step - loss: 23.3116 - val_loss: 20.0874\n",
      "Epoch 3/3\n",
      "4391/4391 [==============================] - 32s 7ms/step - loss: 23.2722 - val_loss: 20.0427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13c86cc18>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_length=train_input.shape[1], input_dim=train_input.shape[2], return_sequences=True))\n",
    "    model.add(LSTM(50, return_sequences=False))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "    LSTMIndicatorPred = model.predict(test_input)\n",
    "    LSTMacc = np.std(LSTMIndicatorPred - test_label.reshape(test_label.shape[0], 1))\n",
    "    return LSTMacc\n",
    "\n",
    "NSS = [[10, 50, 50], [10, 100, 100], [50, 50, 50], [50, 50, 100], [100, 50, 100], [100, 100, 100]]\n",
    "accs = []\n",
    "for nss in NSS:\n",
    "    N, seq_len, sample_gap = nss\n",
    "    if os.path.exists(path=\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "        with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "            (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "    else:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "        with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "            data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "            pickle.dump(data_list, save_data)\n",
    "    \n",
    "    LSTMacc = LSTMModel(train_input, train_label, dev_input, dev_label, test_input, test_label)\n",
    "    accs.append(LSTMacc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13c8fc6d8>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot([\"10 50 50\", \"10 100 100\", \"50 50 50\", \"50 50 100\", \"100 50 100\", \"100 100 100\"], accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we compare the raw model and with PCA to show the effect of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost 1.5397229009697102\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "seq_len = 30\n",
    "sample_gap = 30\n",
    "\n",
    "if os.path.exists(path=\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap)):\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'rb') as load_data:\n",
    "        (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = pickle.load(load_data)\n",
    "else:\n",
    "    (train_input, train_label), (dev_input, dev_label), (test_input, test_label) = DataLoader(\"./data.csv\", N, seq_len, sample_gap)\n",
    "    with open(\"./indicator_data/mydata_{0}_{1}_{2}.pickle\".format(N, seq_len, sample_gap), 'wb') as save_data:\n",
    "        data_list = [(train_input, train_label), (dev_input, dev_label), (test_input, test_label)]\n",
    "        pickle.dump(data_list, save_data)\n",
    "        \n",
    "train_input = train_input.reshape(train_input.shape[0], -1)\n",
    "dev_input = dev_input.reshape(dev_input.shape[0], -1)\n",
    "test_input = test_input.reshape(test_input.shape[0], -1)\n",
    "\n",
    "accs3 = []\n",
    "regressor = AdaRegress(train_input, np.array(train_label), 100, 0)\n",
    "\n",
    "AdaIndicatorPred = regressor.predict(test_input)\n",
    "AdaBoostacc3 = np.std(AdaIndicatorPred - np.array(test_label))\n",
    "accs3.append(AdaBoostacc3)\n",
    "print(\"AdaBoost\", AdaBoostacc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               414848    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 419,249\n",
      "Trainable params: 419,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 15091 samples, validate on 1886 samples\n",
      "Epoch 1/3\n",
      "15091/15091 [==============================] - 6s 419us/step - loss: 2.3779 - val_loss: 2.2221\n",
      "Epoch 2/3\n",
      "15091/15091 [==============================] - 5s 319us/step - loss: 2.2666 - val_loss: 2.1670\n",
      "Epoch 3/3\n",
      "15091/15091 [==============================] - 5s 309us/step - loss: 2.2514 - val_loss: 2.1653\n",
      "DNN 1.4950650310860343\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(train_input.shape[1], ), kernel_initializer='uniform', activation='sigmoid', kernel_regularizer=keras.regularizers.l1(0.)))\n",
    "model.add(Dense(32))\n",
    "model.add(Dense(8))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "model.summary()\n",
    "\n",
    "callback = EarlyStopping(monitor=\"loss\", patience=0.01, verbose=1, mode=\"auto\")\n",
    "model.fit(train_input, train_label, epochs=3, batch_size=32, validation_data=(dev_input, dev_label), callbacks=[callback])\n",
    "\n",
    "DNNRawPred = model.predict(test_input)\n",
    "DNNacc3 = np.std(DNNRawPred - test_label.reshape(test_label.shape[0], 1))\n",
    "accs3.append(DNNacc3)\n",
    "print(\"DNN\", DNNacc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBDT 1.5003095620657034\n"
     ]
    }
   ],
   "source": [
    "regressor = GBDTRegress(train_input, np.array(train_label), 2, 0)\n",
    "\n",
    "GBDTRawPred = regressor.predict(test_input)\n",
    "GBDTacc3 = np.std(GBDTRawPred - np.array(test_label))\n",
    "accs3.append(GBDTacc3)\n",
    "print(\"GBDT\", GBDTacc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest 1.4908335653635423\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegress(train_input, np.array(train_label), 2, 0, 100)\n",
    "\n",
    "RFRawPred = regressor.predict(test_input)\n",
    "RFacc3 = np.std(RFRawPred - np.array(test_label))\n",
    "accs3.append(RFacc3)\n",
    "print(\"RandomForest\", RFacc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x362cbef98>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PCAAcc = [1.5704781815193638, 1.5465264107079268, 1.5416751363111998, 1.5416751363111998]\n",
    "plt.figure()\n",
    "plt.plot(['AdaBoost', 'DNN', 'GBDT', 'RandomForest'], PCAAcc, color='blue', label='PCA')\n",
    "plt.plot(['AdaBoost', 'DNN', 'GBDT', 'RandomForest'], accs3, color='red', label='without PCA')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
